#!/usr/bin/env python3
"""
Test suite for the agentic vulnerability analysis system.

This module tests the AI agent capabilities including intelligent graph traversal,
context-aware analysis, and dynamic decision making.
"""

import os
import json
import tempfile
import shutil
from pathlib import Path
from typing import Dict, List, Any
from unittest import TestCase, main
from dataclasses import dataclass

# Import our agentic vulnerability system
from agentic_vulnerability_system import (
    AgenticVulnerabilityScanner, 
    VulnerabilityReport, 
    ImpactAnalysis, 
    RemediationPlan,
    AgentTraversalResult,
    GraphTraversalAgent
)


@dataclass
class AgenticTestResult:
    """Test result data structure for agentic capabilities."""
    test_name: str
    passed: bool
    message: str
    agent_insights: List[str] = None
    traversal_results: Dict[str, Any] = None


class TestAgenticVulnerabilitySystem(TestCase):
    """Test suite for the agentic vulnerability analysis system."""
    
    def setUp(self):
        """Set up test environment."""
        # Check if OpenAI API key is available
        if not os.getenv("OPENAI_API_KEY"):
            self.skipTest("OPENAI_API_KEY environment variable is required for agentic tests")
        
        self.scanner = AgenticVulnerabilityScanner()
        self.test_results: List[AgenticTestResult] = []
        
        # Test data for known vulnerable packages
        self.known_vulnerable_packages = [
            ("log4j", "2.14.1"),  # Known to have multiple CVEs
            ("fastapi", "0.65.1"),  # CVE-2021-32677 (CSRF vulnerability)
        ]
        
        # Create temporary directory for test reports
        self.temp_dir = tempfile.mkdtemp()
        
    def tearDown(self):
        """Clean up test environment."""
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
        if hasattr(self, 'scanner'):
            self.scanner.close()
    
    def test_1_agentic_package_scanning(self):
        """Test 1: Verify AI agents can intelligently scan packages for vulnerabilities."""
        print("\n" + "="*60)
        print("TEST 1: Agentic Package Scanning")
        print("="*60)
        
        for package_name, version in self.known_vulnerable_packages:
            print(f"\nü§ñ Testing agentic scanning for: {package_name}@{version}")
            
            try:
                # Scan the package with AI agents
                vulnerabilities, traversal_result = self.scanner.scan_package_with_agents(package_name, version)
                
                # Validate vulnerability detection
                if vulnerabilities:
                    print(f"‚úÖ Found {len(vulnerabilities)} vulnerabilities for {package_name}@{version}")
                    
                    # Check that vulnerabilities have required fields
                    for vuln in vulnerabilities:
                        self.assertIsInstance(vuln, VulnerabilityReport)
                        self.assertIsNotNone(vuln.cve_id)
                        self.assertIsNotNone(vuln.severity)
                        self.assertIsNotNone(vuln.description)
                        
                        print(f"  - {vuln.cve_id}: {vuln.severity} - {vuln.description[:100]}...")
                    
                    # Validate agentic traversal results
                    self.assertIsInstance(traversal_result, AgentTraversalResult)
                    self.assertIsNotNone(traversal_result.traversal_strategy)
                    self.assertIsNotNone(traversal_result.reasoning)
                    
                    print(f"ü§ñ Agent Traversal Results:")
                    print(f"  - Strategy: {traversal_result.traversal_strategy}")
                    print(f"  - Paths Explored: {len(traversal_result.paths_explored)}")
                    print(f"  - Critical Nodes: {len(traversal_result.critical_nodes)}")
                    print(f"  - Confidence: {traversal_result.confidence:.2f}")
                    print(f"  - Next Actions: {len(traversal_result.next_actions)}")
                    
                    # For log4j, we expect multiple vulnerabilities and agent insights
                    if package_name == "log4j" and version == "2.14.1":
                        self.assertGreater(len(vulnerabilities), 5, 
                                         f"Expected at least 5 vulnerabilities for log4j@{version}, found {len(vulnerabilities)}")
                        self.assertGreater(traversal_result.confidence, 0.0,
                                         "Agent should have some confidence in its analysis")
                
                else:
                    print(f"‚ö†Ô∏è  No vulnerabilities found for {package_name}@{version}")
                
            except Exception as e:
                print(f"‚ùå Error testing agentic scanning for {package_name}@{version}: {e}")
                self.fail(f"Failed to test agentic scanning for {package_name}@{version}: {e}")
        
        print("\n‚úÖ Test 1 completed: Agentic package scanning")
    
    def test_2_agentic_impact_analysis(self):
        """Test 2: Verify AI agents can perform context-aware impact analysis."""
        print("\n" + "="*60)
        print("TEST 2: Agentic Impact Analysis")
        print("="*60)
        
        # Test with a known vulnerable package
        package_name, version = "log4j", "2.14.1"
        print(f"\nü§ñ Testing agentic impact analysis for: {package_name}@{version}")
        
        try:
            # Scan the package for vulnerabilities
            vulnerabilities, traversal_result = self.scanner.scan_package_with_agents(package_name, version)
            
            if vulnerabilities:
                # Test agentic impact analysis for the first vulnerability
                vuln = vulnerabilities[0]
                print(f"Testing agentic impact analysis for {vuln.cve_id}")
                
                # Perform agentic impact analysis
                impact = self.scanner.analyze_impact_with_agents(vuln)
                
                # Validate impact analysis results
                self.assertIsInstance(impact, ImpactAnalysis)
                self.assertIsInstance(impact.affected_files, int)
                self.assertIsInstance(impact.affected_functions, int)
                self.assertIsInstance(impact.risk_score, float)
                self.assertIsInstance(impact.estimated_impact, str)
                self.assertIsInstance(impact.agent_insights, list)
                
                print(f"  - Affected Files: {impact.affected_files}")
                print(f"  - Affected Functions: {impact.affected_functions}")
                print(f"  - Risk Score: {impact.risk_score:.2f}/1.0")
                print(f"  - Estimated Impact: {impact.estimated_impact}")
                print(f"  - AI Agent Insights: {len(impact.agent_insights)}")
                
                # Show agent insights
                for i, insight in enumerate(impact.agent_insights[:3]):  # Show first 3
                    print(f"    Insight {i+1}: {insight}")
                
                # Validate risk score is within expected range
                self.assertGreaterEqual(impact.risk_score, 0.0)
                self.assertLessEqual(impact.risk_score, 1.0)
                
                # Validate agent insights are present
                self.assertGreater(len(impact.agent_insights), 0,
                                 "AI agent should provide insights")
                
            else:
                print(f"‚ö†Ô∏è  No vulnerabilities found for {package_name}@{version}, skipping impact analysis")
                
        except Exception as e:
            print(f"‚ùå Error testing agentic impact analysis: {e}")
            self.fail(f"Failed to test agentic impact analysis: {e}")
        
        print("\n‚úÖ Test 2 completed: Agentic impact analysis")
    
    def test_3_agentic_remediation_planning(self):
        """Test 3: Verify AI agents can generate intelligent remediation plans."""
        print("\n" + "="*60)
        print("TEST 3: Agentic Remediation Planning")
        print("="*60)
        
        # Test with a known vulnerable package
        package_name, version = "log4j", "2.14.1"
        print(f"\nü§ñ Testing agentic remediation planning for: {package_name}@{version}")
        
        try:
            # Scan the package for vulnerabilities
            vulnerabilities, traversal_result = self.scanner.scan_package_with_agents(package_name, version)
            
            if vulnerabilities:
                # Test agentic remediation planning for the first vulnerability
                vuln = vulnerabilities[0]
                print(f"Testing agentic remediation planning for {vuln.cve_id}")
                
                # Generate agentic remediation plan
                remediation = self.scanner.generate_remediation_with_agents(vuln)
                
                # Validate remediation plan
                self.assertIsInstance(remediation, RemediationPlan)
                self.assertIsInstance(remediation.migration_steps, list)
                self.assertIsInstance(remediation.rollback_procedure, str)
                self.assertIsInstance(remediation.testing_recommendations, list)
                self.assertIsInstance(remediation.estimated_time, str)
                self.assertIsInstance(remediation.agent_recommendations, list)
                
                print(f"  - Migration Steps: {len(remediation.migration_steps)} steps")
                print(f"  - Rollback Procedure: {len(remediation.rollback_procedure)} characters")
                print(f"  - Testing Recommendations: {len(remediation.testing_recommendations)} items")
                print(f"  - Estimated Time: {remediation.estimated_time}")
                print(f"  - AI Agent Recommendations: {len(remediation.agent_recommendations)}")
                
                # Show agent recommendations
                for i, rec in enumerate(remediation.agent_recommendations[:3]):  # Show first 3
                    print(f"    Recommendation {i+1}: {rec}")
                
                # Validate migration steps are not empty
                self.assertGreater(len(remediation.migration_steps), 0,
                                 "Remediation plan should have at least one migration step")
                
                # Validate rollback procedure is not empty
                self.assertGreater(len(remediation.rollback_procedure), 0,
                                 "Remediation plan should have a rollback procedure")
                
                # Validate testing recommendations are not empty
                self.assertGreater(len(remediation.testing_recommendations), 0,
                                 "Remediation plan should have testing recommendations")
                
                # Validate agent recommendations are present
                self.assertGreater(len(remediation.agent_recommendations), 0,
                                 "AI agent should provide recommendations")
                
            else:
                print(f"‚ö†Ô∏è  No vulnerabilities found for {package_name}@{version}, skipping remediation planning")
                
        except Exception as e:
            print(f"‚ùå Error testing agentic remediation planning: {e}")
            self.fail(f"Failed to test agentic remediation planning: {e}")
        
        print("\n‚úÖ Test 3 completed: Agentic remediation planning")
    
    def test_4_graph_traversal_agent_capabilities(self):
        """Test 4: Verify the GraphTraversalAgent has proper AI capabilities."""
        print("\n" + "="*60)
        print("TEST 4: Graph Traversal Agent Capabilities")
        print("="*60)
        
        if not self.scanner.traversal_agent:
            self.skipTest("GraphTraversalAgent not available")
        
        try:
            # Test smart path discovery
            print("\nü§ñ Testing Smart Path Discovery...")
            
            # Create a mock vulnerability for testing
            mock_vuln = VulnerabilityReport(
                cve_id="CVE-2025-TEST",
                package_name="test-package",
                version_affected="1.0.0",
                severity="HIGH",
                description="Test vulnerability for agent capabilities",
                sources=["test"],
                confidence_score=0.9,
                conflicting_reports=False,
                resolution="confirmed"
            )
            
            # Get repository structure
            repo_structure = self.scanner._get_repository_structure()
            
            # Test smart path discovery
            traversal_result = self.scanner.traversal_agent.smart_path_discovery(
                mock_vuln, 
                repo_structure
            )
            
            # Validate traversal result
            self.assertIsInstance(traversal_result, AgentTraversalResult)
            self.assertIsInstance(traversal_result.paths_explored, list)
            self.assertIsInstance(traversal_result.critical_nodes, list)
            self.assertIsInstance(traversal_result.traversal_strategy, str)
            self.assertIsInstance(traversal_result.reasoning, str)
            self.assertIsInstance(traversal_result.confidence, float)
            self.assertIsInstance(traversal_result.next_actions, list)
            
            print(f"  - Traversal Strategy: {traversal_result.traversal_strategy}")
            print(f"  - Paths Explored: {len(traversal_result.paths_explored)}")
            print(f"  - Critical Nodes: {len(traversal_result.critical_nodes)}")
            print(f"  - Confidence: {traversal_result.confidence:.2f}")
            print(f"  - Next Actions: {len(traversal_result.next_actions)}")
            
            # Test context-aware analysis
            print("\nü§ñ Testing Context-Aware Analysis...")
            
            context_analysis = self.scanner.traversal_agent.context_aware_analysis(
                "test_file.py",
                mock_vuln,
                ["import test_package", "from test_package import function"]
            )
            
            # Validate context analysis
            self.assertIsInstance(context_analysis, dict)
            
            print(f"  - Context Analysis Keys: {list(context_analysis.keys())}")
            
            # Test dynamic traversal
            print("\nü§ñ Testing Dynamic Traversal...")
            
            dynamic_strategy = self.scanner.traversal_agent.dynamic_traversal(repo_structure)
            
            # Validate dynamic strategy
            self.assertIsInstance(dynamic_strategy, dict)
            
            print(f"  - Dynamic Strategy Keys: {list(dynamic_strategy.keys())}")
            
        except Exception as e:
            print(f"‚ùå Error testing graph traversal agent capabilities: {e}")
            self.fail(f"Failed to test graph traversal agent capabilities: {e}")
        
        print("\n‚úÖ Test 4 completed: Graph traversal agent capabilities")
    
    def test_5_agent_tools_functionality(self):
        """Test 5: Verify the AI agent tools work correctly."""
        print("\n" + "="*60)
        print("TEST 5: Agent Tools Functionality")
        print("="*60)
        
        if not self.scanner.traversal_agent:
            self.skipTest("GraphTraversalAgent not available")
        
        try:
            # Test query_dependency_graph tool
            print("\nüîß Testing query_dependency_graph tool...")
            result = self.scanner.traversal_agent._query_dependency_graph(
                "MATCH (n) RETURN count(n) as total_nodes LIMIT 1"
            )
            self.assertIsInstance(result, str)
            print(f"  - Query Result: {result[:100]}...")
            
            # Test analyze_usage_patterns tool
            print("\nüîß Testing analyze_usage_patterns tool...")
            result = self.scanner.traversal_agent._analyze_usage_patterns("requests")
            self.assertIsInstance(result, str)
            print(f"  - Usage Patterns: {result[:100]}...")
            
            # Test find_critical_paths tool
            print("\nüîß Testing find_critical_paths tool...")
            result = self.scanner.traversal_agent._find_critical_paths("requests")
            self.assertIsInstance(result, str)
            print(f"  - Critical Paths: {result[:100]}...")
            
            # Test assess_risk_context tool
            print("\nüîß Testing assess_risk_context tool...")
            result = self.scanner.traversal_agent._assess_risk_context("requests", "HIGH")
            self.assertIsInstance(result, str)
            print(f"  - Risk Context: {result[:100]}...")
            
        except Exception as e:
            print(f"‚ùå Error testing agent tools: {e}")
            self.fail(f"Failed to test agent tools: {e}")
        
        print("\n‚úÖ Test 5 completed: Agent tools functionality")
    
    def test_6_end_to_end_agentic_workflow(self):
        """Test 6: Verify the complete agentic workflow from scanning to remediation."""
        print("\n" + "="*60)
        print("TEST 6: End-to-End Agentic Workflow")
        print("="*60)
        
        # Test with a known vulnerable package
        package_name, version = "log4j", "2.14.1"
        print(f"\nü§ñ Testing complete agentic workflow for: {package_name}@{version}")
        
        try:
            # Step 1: Agentic package scanning
            print("Step 1: Agentic package scanning...")
            vulnerabilities, traversal_result = self.scanner.scan_package_with_agents(package_name, version)
            
            if vulnerabilities:
                print(f"  - Found {len(vulnerabilities)} vulnerabilities")
                print(f"  - Agent confidence: {traversal_result.confidence:.2f}")
                
                # Step 2: Agentic impact analysis
                print("Step 2: Agentic impact analysis...")
                impacts = []
                for vuln in vulnerabilities[:3]:  # Limit to first 3 for testing
                    impact = self.scanner.analyze_impact_with_agents(vuln)
                    impacts.append(impact)
                    print(f"    - {vuln.cve_id}: Risk Score {impact.risk_score:.2f}, Impact {impact.estimated_impact}")
                    print(f"      AI Insights: {len(impact.agent_insights)}")
                
                # Step 3: Agentic remediation planning
                print("Step 3: Agentic remediation planning...")
                remediations = []
                for vuln in vulnerabilities[:3]:  # Limit to first 3 for testing
                    remediation = self.scanner.generate_remediation_with_agents(vuln)
                    remediations.append(remediation)
                    print(f"    - {vuln.cve_id}: {len(remediation.migration_steps)} migration steps")
                    print(f"      AI Recommendations: {len(remediation.agent_recommendations)}")
                
                # Step 4: Validate agentic insights
                print("Step 4: Validating agentic insights...")
                
                # Check that we have agent insights
                total_insights = sum(len(impact.agent_insights) for impact in impacts)
                total_recommendations = sum(len(remediation.agent_recommendations) for remediation in remediations)
                
                print(f"  - Total AI Insights: {total_insights}")
                print(f"  - Total AI Recommendations: {total_recommendations}")
                print(f"  - Agent Traversal Strategy: {traversal_result.traversal_strategy}")
                print(f"  - Agent Confidence: {traversal_result.confidence:.2f}")
                
                # Validate that agents provided insights
                self.assertGreater(total_insights, 0, "AI agents should provide insights")
                self.assertGreater(total_recommendations, 0, "AI agents should provide recommendations")
                self.assertGreater(traversal_result.confidence, 0.0, "Agent should have confidence in analysis")
                
                print("‚úÖ Complete agentic workflow executed successfully!")
                
            else:
                print(f"‚ö†Ô∏è  No vulnerabilities found for {package_name}@{version}, workflow test limited")
                
        except Exception as e:
            print(f"‚ùå Error testing end-to-end agentic workflow: {e}")
            self.fail(f"Failed to test end-to-end agentic workflow: {e}")
        
        print("\n‚úÖ Test 6 completed: End-to-end agentic workflow")
    
    def run_all_agentic_tests(self):
        """Run all agentic tests and provide a summary."""
        print("\n" + "="*80)
        print("ü§ñ RUNNING AGENTIC VULNERABILITY SYSTEM TEST SUITE")
        print("="*80)
        
        test_methods = [
            self.test_1_agentic_package_scanning,
            self.test_2_agentic_impact_analysis,
            self.test_3_agentic_remediation_planning,
            self.test_4_graph_traversal_agent_capabilities,
            self.test_5_agent_tools_functionality,
            self.test_6_end_to_end_agentic_workflow,
        ]
        
        passed = 0
        failed = 0
        
        for test_method in test_methods:
            try:
                test_method()
                passed += 1
            except Exception as e:
                failed += 1
                print(f"\n‚ùå {test_method.__name__} FAILED: {e}")
        
        print("\n" + "="*80)
        print("üìä AGENTIC TEST SUMMARY")
        print("="*80)
        print(f"‚úÖ Tests Passed: {passed}")
        print(f"‚ùå Tests Failed: {failed}")
        print(f"üìà Success Rate: {passed/(passed+failed)*100:.1f}%")
        
        if failed == 0:
            print("\nüéâ ALL AGENTIC TESTS PASSED! The agentic vulnerability system is working correctly.")
            print("ü§ñ AI agents are successfully providing intelligent analysis and recommendations.")
        else:
            print(f"\n‚ö†Ô∏è  {failed} test(s) failed. Please review the errors above.")
        
        return passed, failed


def main():
    """Main function to run the agentic test suite."""
    print("ü§ñ Agentic Vulnerability System Test Suite")
    print("="*50)
    
    # Create test instance
    test_suite = TestAgenticVulnerabilitySystem()
    
    # Set up test environment
    test_suite.setUp()
    
    try:
        # Run all tests
        passed, failed = test_suite.run_all_agentic_tests()
        
        # Return appropriate exit code
        return 0 if failed == 0 else 1
        
    finally:
        # Clean up
        test_suite.tearDown()


if __name__ == "__main__":
    exit(main()) 