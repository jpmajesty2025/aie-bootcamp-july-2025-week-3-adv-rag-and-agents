"""
Agentic Vulnerability Analysis and Remediation System

This script provides comprehensive vulnerability detection, analysis, and remediation
using AI-powered graph traversal and multiple vulnerability databases.

Required packages:
pip install neo4j langchain langchain-openai requests semver packaging rich
"""

import os
import json
import requests
import semver
from datetime import datetime, timedelta
from typing import List, Dict, Set, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from pathlib import Path
import logging

# Environment and configuration
from dotenv import load_dotenv

# LangChain imports
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_community.graphs import Neo4jGraph
from langchain_core.output_parsers import JsonOutputParser

# Neo4j imports
from neo4j import GraphDatabase
from neo4j.exceptions import ServiceUnavailable, AuthError

# Rich for better console output
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn

# Load environment variables
load_dotenv()

# Setup console for rich output
console = Console()


@dataclass
class VulnerabilityReport:
    """Data class for vulnerability information"""
    cve_id: str
    package_name: str
    version_affected: str
    severity: str
    description: str
    sources: List[str]  # ["nvd", "github", "snyk"]
    confidence_score: float  # 0.0-1.0
    conflicting_reports: bool
    resolution: str  # "confirmed", "disputed", "needs_review"
    published_date: Optional[str] = None
    last_modified: Optional[str] = None
    cvss_score: Optional[float] = None
    affected_versions: Optional[List[str]] = None
    fixed_versions: Optional[List[str]] = None


@dataclass
class ImpactAnalysis:
    """Data class for impact analysis results"""
    vulnerable_package: str
    affected_files: List[str]
    affected_functions: List[str]
    risk_score: float  # 0.0-1.0
    usage_patterns: List[str]
    reachable_paths: List[str]
    estimated_impact: str  # "low", "medium", "high", "critical"


@dataclass
class RemediationPlan:
    """Data class for remediation recommendations"""
    package_name: str
    current_version: str
    recommended_version: str
    breaking_changes: List[str]
    migration_steps: List[str]
    rollback_procedure: List[str]
    testing_recommendations: List[str]
    estimated_time: str
    risk_level: str  # "low", "medium", "high"


class VulnerabilityScanner:
    """Scans packages against multiple vulnerability databases"""
    
    def __init__(self):
        """Initialize the vulnerability scanner"""
        self.nvd_base_url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
        self.github_api_url = "https://api.github.com/advisories"
        self.snyk_api_url = "https://snyk.io/api/v1"
        
        # API keys (optional)
        self.github_token = os.getenv("GITHUB_TOKEN")
        self.snyk_token = os.getenv("SNYK_TOKEN")
        
        # Rate limiting
        self.nvd_rate_limit = 5  # requests per second
        self.last_nvd_request = datetime.now()
    
    def scan_package(self, package_name: str, version: str) -> List[VulnerabilityReport]:
        """Scan a package against all vulnerability databases"""
        console.print(f"🔍 Scanning {package_name}@{version} for vulnerabilities...", style="blue")
        
        vulnerabilities = []
        
        # Scan NVD
        try:
            nvd_vulns = self._scan_nvd(package_name, version)
            vulnerabilities.extend(nvd_vulns)
        except Exception as e:
            console.print(f"⚠️ Failed to scan NVD: {e}", style="yellow")
        
        # Scan GitHub Security Advisories
        try:
            github_vulns = self._scan_github(package_name, version)
            vulnerabilities.extend(github_vulns)
        except Exception as e:
            console.print(f"⚠️ Failed to scan GitHub: {e}", style="yellow")
        
        # Scan Snyk (if token available)
        if self.snyk_token:
            try:
                snyk_vulns = self._scan_snyk(package_name, version)
                vulnerabilities.extend(snyk_vulns)
            except Exception as e:
                console.print(f"⚠️ Failed to scan Snyk: {e}", style="yellow")
        
        # Resolve conflicts and calculate confidence
        resolved_vulns = self._resolve_conflicts(vulnerabilities)
        
        console.print(f"✅ Found {len(resolved_vulns)} vulnerabilities", style="green")
        return resolved_vulns
    
    def _scan_nvd(self, package_name: str, version: str) -> List[VulnerabilityReport]:
        """Scan NVD for vulnerabilities"""
        # Rate limiting
        time_since_last = datetime.now() - self.last_nvd_request
        if time_since_last.total_seconds() < 1.0 / self.nvd_rate_limit:
            import time
            time.sleep(1.0 / self.nvd_rate_limit - time_since_last.total_seconds())
        
        # Query NVD API
        params = {
            "keyword": package_name,
            "versionStart": version,
            "versionEnd": version
        }
        
        response = requests.get(self.nvd_base_url, params=params)
        response.raise_for_status()
        
        data = response.json()
        vulnerabilities = []
        
        for vuln in data.get("vulnerabilities", []):
            cve = vuln["cve"]
            
            # Check if this package is actually affected
            if self._is_package_affected(cve, package_name, version):
                vuln_report = VulnerabilityReport(
                    cve_id=cve["id"],
                    package_name=package_name,
                    version_affected=version,
                    severity=self._extract_severity(cve),
                    description=cve.get("descriptions", [{}])[0].get("value", ""),
                    sources=["nvd"],
                    confidence_score=0.9,  # NVD is authoritative
                    conflicting_reports=False,
                    resolution="confirmed",
                    published_date=cve.get("published"),
                    last_modified=cve.get("lastModified"),
                    cvss_score=self._extract_cvss_score(cve),
                    affected_versions=self._extract_affected_versions(cve, package_name),
                    fixed_versions=self._extract_fixed_versions(cve, package_name)
                )
                vulnerabilities.append(vuln_report)
        
        self.last_nvd_request = datetime.now()
        return vulnerabilities
    
    def _scan_github(self, package_name: str, version: str) -> List[VulnerabilityReport]:
        """Scan GitHub Security Advisories"""
        if not self.github_token:
            return []
        
        headers = {"Authorization": f"token {self.github_token}"}
        params = {"package": package_name}
        
        response = requests.get(self.github_api_url, headers=headers, params=params)
        response.raise_for_status()
        
        data = response.json()
        vulnerabilities = []
        
        for advisory in data:
            if self._is_version_affected(advisory, version):
                vuln_report = VulnerabilityReport(
                    cve_id=advisory.get("cve_id", f"GHSA-{advisory['ghsa_id']}"),
                    package_name=package_name,
                    version_affected=version,
                    severity=advisory.get("severity", "unknown"),
                    description=advisory.get("description", ""),
                    sources=["github"],
                    confidence_score=0.8,
                    conflicting_reports=False,
                    resolution="confirmed",
                    published_date=advisory.get("published_at"),
                    last_modified=advisory.get("updated_at")
                )
                vulnerabilities.append(vuln_report)
        
        return vulnerabilities
    
    def _scan_snyk(self, package_name: str, version: str) -> List[VulnerabilityReport]:
        """Scan Snyk vulnerability database"""
        if not self.snyk_token:
            return []
        
        headers = {"Authorization": f"Bearer {self.snyk_token}"}
        url = f"{self.snyk_api_url}/test/npm/{package_name}/{version}"
        
        response = requests.post(url, headers=headers)
        response.raise_for_status()
        
        data = response.json()
        vulnerabilities = []
        
        for vuln in data.get("vulnerabilities", []):
            vuln_report = VulnerabilityReport(
                cve_id=vuln.get("id", f"SNYK-{vuln.get('title', '')}"),
                package_name=package_name,
                version_affected=version,
                severity=vuln.get("severity", "unknown"),
                description=vuln.get("description", ""),
                sources=["snyk"],
                confidence_score=0.7,
                conflicting_reports=False,
                resolution="confirmed"
            )
            vulnerabilities.append(vuln_report)
        
        return vulnerabilities
    
    def _is_package_affected(self, cve: Dict, package_name: str, version: str) -> bool:
        """Check if a package is affected by a CVE"""
        # Check configurations for the specific package
        for config in cve.get("configurations", []):
            for node in config.get("nodes", []):
                for cpe_match in node.get("cpeMatch", []):
                    cpe = cpe_match.get("criteria", "")
                    if package_name.lower() in cpe.lower():
                        # Check version range
                        if self._is_version_in_range(version, cpe_match):
                            return True
        return False
    
    def _is_version_affected(self, advisory: Dict, version: str) -> bool:
        """Check if a version is affected by a GitHub advisory"""
        # Simplified version checking - in practice, this would be more sophisticated
        vulnerable_ranges = advisory.get("vulnerable_version_range", [])
        for range_str in vulnerable_ranges:
            if self._is_version_in_range(version, {"versionStartIncluding": range_str}):
                return True
        return False
    
    def _is_version_in_range(self, version: str, range_info: Dict) -> bool:
        """Check if a version is within a specified range"""
        try:
            # Simplified version comparison - would need more sophisticated logic
            return True  # Placeholder
        except:
            return False
    
    def _extract_severity(self, cve: Dict) -> str:
        """Extract severity from CVE data"""
        metrics = cve.get("metrics", {})
        if "cvssMetricV31" in metrics:
            return metrics["cvssMetricV31"][0]["cvssData"]["baseSeverity"]
        elif "cvssMetricV30" in metrics:
            return metrics["cvssMetricV30"][0]["cvssData"]["baseSeverity"]
        return "unknown"
    
    def _extract_cvss_score(self, cve: Dict) -> Optional[float]:
        """Extract CVSS score from CVE data"""
        metrics = cve.get("metrics", {})
        if "cvssMetricV31" in metrics:
            return metrics["cvssMetricV31"][0]["cvssData"]["baseScore"]
        elif "cvssMetricV30" in metrics:
            return metrics["cvssMetricV30"][0]["cvssData"]["baseScore"]
        return None
    
    def _extract_affected_versions(self, cve: Dict, package_name: str) -> List[str]:
        """Extract affected versions from CVE data"""
        # Simplified - would need more sophisticated parsing
        return []
    
    def _extract_fixed_versions(self, cve: Dict, package_name: str) -> List[str]:
        """Extract fixed versions from CVE data"""
        # Simplified - would need more sophisticated parsing
        return []
    
    def _resolve_conflicts(self, vulnerabilities: List[VulnerabilityReport]) -> List[VulnerabilityReport]:
        """Resolve conflicts between different vulnerability sources"""
        # Group by CVE ID
        vuln_groups = {}
        for vuln in vulnerabilities:
            if vuln.cve_id not in vuln_groups:
                vuln_groups[vuln.cve_id] = []
            vuln_groups[vuln.cve_id].append(vuln)
        
        resolved_vulns = []
        
        for cve_id, vuln_list in vuln_groups.items():
            if len(vuln_list) == 1:
                # Single source, no conflict
                resolved_vulns.append(vuln_list[0])
            else:
                # Multiple sources, resolve conflict
                resolved_vuln = self._resolve_single_conflict(vuln_list)
                resolved_vulns.append(resolved_vuln)
        
        return resolved_vulns
    
    def _resolve_single_conflict(self, vuln_list: List[VulnerabilityReport]) -> VulnerabilityReport:
        """Resolve conflict for a single CVE"""
        # Use the first vulnerability as base
        base_vuln = vuln_list[0]
        
        # Combine sources
        all_sources = []
        for vuln in vuln_list:
            all_sources.extend(vuln.sources)
        
        # Calculate confidence based on number of sources
        confidence = min(1.0, 0.5 + len(set(all_sources)) * 0.2)
        
        # Determine resolution
        nvd_reports = [v for v in vuln_list if "nvd" in v.sources]
        if nvd_reports:
            resolution = "confirmed"
        else:
            resolution = "needs_review"
        
        # Create resolved vulnerability
        resolved_vuln = VulnerabilityReport(
            cve_id=base_vuln.cve_id,
            package_name=base_vuln.package_name,
            version_affected=base_vuln.version_affected,
            severity=base_vuln.severity,
            description=base_vuln.description,
            sources=list(set(all_sources)),
            confidence_score=confidence,
            conflicting_reports=len(vuln_list) > 1,
            resolution=resolution,
            published_date=base_vuln.published_date,
            last_modified=base_vuln.last_modified,
            cvss_score=base_vuln.cvss_score,
            affected_versions=base_vuln.affected_versions,
            fixed_versions=base_vuln.fixed_versions
        )
        
        return resolved_vuln


class GraphTraversalAgent:
    """AI-powered agent for intelligent graph traversal and analysis"""
    
    def __init__(self, llm: ChatOpenAI, graph_db: Neo4jGraph):
        """Initialize the graph traversal agent"""
        self.llm = llm
        self.graph_db = graph_db
        
        # Setup prompts for different analysis tasks
        self.path_discovery_prompt = PromptTemplate(
            input_variables=["vulnerability_info", "repository_structure"],
            template="""You are an AI agent that analyzes dependency graphs to find the optimal paths for vulnerability impact assessment.

Vulnerability Information:
{vulnerability_info}

Repository Structure:
{repository_structure}

Based on this information, determine the optimal traversal strategy to assess the impact of this vulnerability. Consider:
1. Which files are most likely to be affected
2. What traversal paths will give the most comprehensive coverage
3. How to prioritize high-impact areas

Return your analysis as JSON with the following structure:
{{
    "traversal_strategy": "description of the approach",
    "priority_paths": ["list of high-priority paths to investigate"],
    "focus_areas": ["specific areas to concentrate on"],
    "risk_factors": ["factors that increase risk"]
}}"""
        )
        
        self.context_analysis_prompt = PromptTemplate(
            input_variables=["file_path", "vulnerability_info", "usage_patterns"],
            template="""You are an AI agent that performs context-aware analysis of vulnerability impact.

File: {file_path}
Vulnerability: {vulnerability_info}
Usage Patterns: {usage_patterns}

Analyze the real-world risk of this vulnerability in this specific file. Consider:
1. How the vulnerable package/function is actually used
2. Whether the vulnerable code path is reachable
3. The severity of impact if exploited
4. Mitigating factors

Return your analysis as JSON:
{{
    "risk_level": "low/medium/high/critical",
    "confidence": 0.0-1.0,
    "usage_analysis": "description of how the vulnerable code is used",
    "reachability": "whether vulnerable code path is reachable",
    "impact_assessment": "description of potential impact",
    "mitigating_factors": ["list of factors that reduce risk"]
}}"""
        )
    
    def smart_path_discovery(self, vulnerability_info: VulnerabilityReport, repository_structure: Dict) -> Dict:
        """Determine optimal traversal paths for vulnerability analysis"""
        try:
            # Prepare input for LLM
            vuln_info_str = f"""
            CVE: {vulnerability_info.cve_id}
            Package: {vulnerability_info.package_name}
            Version: {vulnerability_info.version_affected}
            Severity: {vulnerability_info.severity}
            Description: {vulnerability_info.description}
            """
            
            # Query LLM for traversal strategy
            response = self.llm.invoke(
                self.path_discovery_prompt.format(
                    vulnerability_info=vuln_info_str,
                    repository_structure=json.dumps(repository_structure, indent=2)
                )
            )
            
            # Parse response
            parser = JsonOutputParser()
            strategy = parser.parse(response.content)
            
            return strategy
            
        except Exception as e:
            console.print(f"⚠️ Failed to generate traversal strategy: {e}", style="yellow")
            # Fallback to basic strategy
            return {
                "traversal_strategy": "basic_dependency_trace",
                "priority_paths": [f"Package:{vulnerability_info.package_name}"],
                "focus_areas": ["all_dependent_files"],
                "risk_factors": ["direct_dependency"]
            }
    
    def context_aware_analysis(self, file_path: str, vulnerability_info: VulnerabilityReport, usage_patterns: List[str]) -> Dict:
        """Perform context-aware analysis of vulnerability impact"""
        try:
            # Query LLM for context analysis
            response = self.llm.invoke(
                self.context_analysis_prompt.format(
                    file_path=file_path,
                    vulnerability_info=f"{vulnerability_info.cve_id}: {vulnerability_info.description}",
                    usage_patterns=", ".join(usage_patterns)
                )
            )
            
            # Parse response
            parser = JsonOutputParser()
            analysis = parser.parse(response.content)
            
            return analysis
            
        except Exception as e:
            console.print(f"⚠️ Failed to perform context analysis: {e}", style="yellow")
            # Fallback to basic analysis
            return {
                "risk_level": "medium",
                "confidence": 0.5,
                "usage_analysis": "Unable to analyze usage patterns",
                "reachability": "unknown",
                "impact_assessment": "Standard impact assessment",
                "mitigating_factors": []
            }
    
    def dynamic_traversal(self, repository_structure: Dict) -> Dict:
        """Adapt traversal strategy based on repository characteristics"""
        # Analyze repository structure to determine optimal approach
        file_count = repository_structure.get("total_files", 0)
        language_distribution = repository_structure.get("languages", {})
        
        if file_count > 1000:
            strategy = "focused_traversal"
            focus = "high_impact_areas"
        elif "Python" in language_distribution and language_distribution["Python"] > 0.8:
            strategy = "deep_python_analysis"
            focus = "python_specific_patterns"
        else:
            strategy = "comprehensive_traversal"
            focus = "all_dependencies"
        
        return {
            "strategy": strategy,
            "focus": focus,
            "file_count": file_count,
            "languages": language_distribution
        }


class VulnerabilitySystem:
    """Main vulnerability analysis and remediation system"""
    
    def __init__(self, 
                 neo4j_uri: Optional[str] = None,
                 neo4j_username: Optional[str] = None,
                 neo4j_password: Optional[str] = None,
                 openai_api_key: Optional[str] = None,
                 model_name: str = "gpt-4o-mini"):
        """Initialize the vulnerability system"""
        # Load configuration from environment variables
        self.neo4j_uri = neo4j_uri or os.getenv("NEO4J_URI")
        self.neo4j_username = neo4j_username or os.getenv("NEO4J_USERNAME")
        self.neo4j_password = neo4j_password or os.getenv("NEO4J_PASSWORD")
        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        
        if not all([self.neo4j_uri, self.neo4j_username, self.neo4j_password]):
            raise ValueError("Missing Neo4j configuration. Please set NEO4J_URI, NEO4J_USERNAME, and NEO4J_PASSWORD environment variables.")
        
        # Initialize components
        self.driver = GraphDatabase.driver(
            self.neo4j_uri, 
            auth=(self.neo4j_username, self.neo4j_password)
        )
        
        self.graph_db = Neo4jGraph(enhanced_schema=True)
        
        if self.openai_api_key:
            self.llm = ChatOpenAI(temperature=0, model=model_name)
        else:
            self.llm = None
            console.print("⚠️ OpenAI API key not provided. LLM features will be disabled.", style="yellow")
        
        # Initialize subsystems
        self.scanner = VulnerabilityScanner()
        if self.llm:
            self.agent = GraphTraversalAgent(self.llm, self.graph_db)
        else:
            self.agent = None
        
        console.print("✅ Vulnerability System initialized successfully", style="green")
    
    def analyze_repository(self, repo_url: str) -> Dict[str, Any]:
        """Perform comprehensive vulnerability analysis of a repository"""
        console.print(f"🔍 Starting vulnerability analysis for: {repo_url}", style="bold blue")
        
        try:
            # Get repository packages
            packages = self._get_repository_packages(repo_url)
            console.print(f"Found {len(packages)} packages to analyze", style="blue")
            
            # Scan packages for vulnerabilities
            all_vulnerabilities = []
            for package_name, version in packages:
                vulns = self.scanner.scan_package(package_name, version)
                all_vulnerabilities.extend(vulns)
            
            # Analyze impact for each vulnerability
            impact_analyses = []
            for vuln in all_vulnerabilities:
                impact = self._analyze_vulnerability_impact(vuln, repo_url)
                impact_analyses.append(impact)
            
            # Generate remediation plans
            remediation_plans = []
            for vuln in all_vulnerabilities:
                plan = self._generate_remediation_plan(vuln)
                remediation_plans.append(plan)
            
            # Generate comprehensive report
            report = self._generate_comprehensive_report(
                repo_url, all_vulnerabilities, impact_analyses, remediation_plans
            )
            
            console.print("✅ Vulnerability analysis completed", style="green")
            return report
            
        except Exception as e:
            console.print(f"❌ Failed to analyze repository: {e}", style="red")
            raise
    
    def _get_repository_packages(self, repo_url: str) -> List[Tuple[str, str]]:
        """Get all packages used by a repository"""
        try:
            with self.driver.session() as session:
                result = session.run("""
                    MATCH (r:Repository {url: $repo_url})-[:USES_PACKAGE]->(p:Package)
                    RETURN p.name as name, p.version as version
                """, repo_url=repo_url)
                
                packages = [(row["name"], row["version"]) for row in result]
                return packages
                
        except Exception as e:
            console.print(f"❌ Failed to get repository packages: {e}", style="red")
            return []
    
    def _analyze_vulnerability_impact(self, vulnerability: VulnerabilityReport, repo_url: str) -> ImpactAnalysis:
        """Analyze the impact of a vulnerability using graph traversal"""
        console.print(f"📊 Analyzing impact of {vulnerability.cve_id}...", style="blue")
        
        try:
            # Get repository structure
            repo_structure = self._get_repository_structure(repo_url)
            
            # Use AI agent for intelligent analysis if available
            if self.agent:
                traversal_strategy = self.agent.smart_path_discovery(vulnerability, repo_structure)
                console.print(f"🤖 AI Agent Strategy: {traversal_strategy['traversal_strategy']}", style="cyan")
            else:
                traversal_strategy = {"traversal_strategy": "basic_traversal"}
            
            # Find affected files
            affected_files = self._find_affected_files(vulnerability.package_name, repo_url)
            
            # Find affected functions
            affected_functions = self._find_affected_functions(vulnerability.package_name, repo_url)
            
            # Calculate risk score
            risk_score = self._calculate_risk_score(vulnerability, len(affected_files), len(affected_functions))
            
            # Analyze usage patterns
            usage_patterns = self._analyze_usage_patterns(vulnerability.package_name, repo_url)
            
            # Find reachable paths
            reachable_paths = self._find_reachable_paths(vulnerability.package_name, repo_url)
            
            # Determine estimated impact
            estimated_impact = self._estimate_impact(risk_score, len(affected_files))
            
            return ImpactAnalysis(
                vulnerable_package=vulnerability.package_name,
                affected_files=affected_files,
                affected_functions=affected_functions,
                risk_score=risk_score,
                usage_patterns=usage_patterns,
                reachable_paths=reachable_paths,
                estimated_impact=estimated_impact
            )
            
        except Exception as e:
            console.print(f"❌ Failed to analyze vulnerability impact: {e}", style="red")
            # Return basic impact analysis
            return ImpactAnalysis(
                vulnerable_package=vulnerability.package_name,
                affected_files=[],
                affected_functions=[],
                risk_score=0.5,
                usage_patterns=[],
                reachable_paths=[],
                estimated_impact="unknown"
            )
    
    def _get_repository_structure(self, repo_url: str) -> Dict:
        """Get repository structure information"""
        try:
            with self.driver.session() as session:
                result = session.run("""
                    MATCH (r:Repository {url: $repo_url})-[:BELONGS_TO]-(f:File)
                    RETURN count(f) as total_files,
                           f.language as language
                """, repo_url=repo_url)
                
                files = list(result)
                total_files = sum(row["total_files"] for row in files)
                
                # Count languages
                languages = {}
                for row in files:
                    lang = row["language"]
                    if lang:
                        languages[lang] = languages.get(lang, 0) + 1
                
                return {
                    "total_files": total_files,
                    "languages": languages
                }
                
        except Exception as e:
            console.print(f"❌ Failed to get repository structure: {e}", style="red")
            return {"total_files": 0, "languages": {}}
    
    def _find_affected_files(self, package_name: str, repo_url: str) -> List[str]:
        """Find files that depend on a vulnerable package (including complex imports)"""
        try:
            with self.driver.session() as session:
                # Find files with direct imports, wildcard imports, and dynamic imports
                result = session.run("""
                    MATCH (r:Repository {url: $repo_url})-[:BELONGS_TO]-(f:File)
                    MATCH (f)-[rel:IMPORTS|IMPORTS_FROM|WILDCARD_IMPORTS|DYNAMIC_IMPORTS]->(m:Module)
                    WHERE m.name CONTAINS $package_name OR m.name = $package_name
                    RETURN DISTINCT f.path as file_path
                """, repo_url=repo_url, package_name=package_name)
                
                affected_files = [row["file_path"] for row in result]
                
                # Also find files that depend on packages that transitively depend on the vulnerable package
                transitive_result = session.run("""
                    MATCH (r:Repository {url: $repo_url})-[:BELONGS_TO]-(f:File)
                    MATCH (f)-[:IMPORTS|IMPORTS_FROM|WILDCARD_IMPORTS|DYNAMIC_IMPORTS]->(m:Module)
                    MATCH (m)-[:TRANSITIVE_DEPENDS_ON*1..3]->(vuln_pkg:Package)
                    WHERE vuln_pkg.name = $package_name
                    RETURN DISTINCT f.path as file_path
                """, repo_url=repo_url, package_name=package_name)
                
                transitive_files = [row["file_path"] for row in transitive_result]
                
                # Combine and remove duplicates
                all_affected_files = list(set(affected_files + transitive_files))
                
                return all_affected_files
                
        except Exception as e:
            console.print(f"❌ Failed to find affected files: {e}", style="red")
            return []
    
    def _find_affected_functions(self, package_name: str, repo_url: str) -> List[str]:
        """Find functions that depend on a vulnerable package"""
        try:
            with self.driver.session() as session:
                result = session.run("""
                    MATCH (r:Repository {url: $repo_url})-[:BELONGS_TO]-(f:File)
                    MATCH (f)-[:IMPORTS_SPECIFIC]->(func:Function)
                    WHERE func.module CONTAINS $package_name
                    RETURN func.full_name as function_name
                """, repo_url=repo_url, package_name=package_name)
                
                return [row["function_name"] for row in result]
                
        except Exception as e:
            console.print(f"❌ Failed to find affected functions: {e}", style="red")
            return []
    
    def _calculate_risk_score(self, vulnerability: VulnerabilityReport, affected_files: int, affected_functions: int) -> float:
        """Calculate risk score based on vulnerability and impact"""
        # Base score from CVSS
        base_score = vulnerability.cvss_score or 5.0
        
        # Impact multiplier based on affected files/functions
        impact_multiplier = 1.0 + (affected_files * 0.01) + (affected_functions * 0.02)
        
        # Confidence adjustment
        confidence_adjustment = vulnerability.confidence_score
        
        # Calculate final risk score (0.0-1.0)
        risk_score = min(1.0, (base_score / 10.0) * impact_multiplier * confidence_adjustment)
        
        return risk_score
    
    def _analyze_usage_patterns(self, package_name: str, repo_url: str) -> List[str]:
        """Analyze how a package is used in the repository (including complex imports)"""
        try:
            with self.driver.session() as session:
                result = session.run("""
                    MATCH (r:Repository {url: $repo_url})-[:BELONGS_TO]-(f:File)
                    MATCH (f)-[rel:IMPORTS|IMPORTS_FROM|IMPORTS_SPECIFIC|WILDCARD_IMPORTS|DYNAMIC_IMPORTS]->(m:Module)
                    WHERE m.name CONTAINS $package_name OR m.name = $package_name
                    RETURN type(rel) as import_type, count(rel) as count
                    ORDER BY count DESC
                """, repo_url=repo_url, package_name=package_name)
                
                patterns = []
                for row in result:
                    import_type = row['import_type']
                    count = row['count']
                    
                    # Add descriptive labels for different import types
                    if import_type == "WILDCARD_IMPORTS":
                        patterns.append(f"Wildcard imports: {count} uses (imports all symbols)")
                    elif import_type == "DYNAMIC_IMPORTS":
                        patterns.append(f"Dynamic imports: {count} uses (runtime imports)")
                    elif import_type == "IMPORTS_SPECIFIC":
                        patterns.append(f"Specific function imports: {count} uses")
                    elif import_type == "IMPORTS_FROM":
                        patterns.append(f"From imports: {count} uses")
                    else:
                        patterns.append(f"{import_type}: {count} uses")
                
                # Also check for transitive dependencies
                transitive_result = session.run("""
                    MATCH (r:Repository {url: $repo_url})-[:BELONGS_TO]-(f:File)
                    MATCH (f)-[:IMPORTS|IMPORTS_FROM|WILDCARD_IMPORTS|DYNAMIC_IMPORTS]->(m:Module)
                    MATCH (m)-[:TRANSITIVE_DEPENDS_ON*1..3]->(vuln_pkg:Package)
                    WHERE vuln_pkg.name = $package_name
                    RETURN count(DISTINCT f) as transitive_count
                """, repo_url=repo_url, package_name=package_name)
                
                transitive_count = transitive_result.single()["transitive_count"]
                if transitive_count > 0:
                    patterns.append(f"Transitive dependencies: {transitive_count} files affected")
                
                return patterns
                
        except Exception as e:
            console.print(f"❌ Failed to analyze usage patterns: {e}", style="red")
            return []
    
    def _find_reachable_paths(self, package_name: str, repo_url: str) -> List[str]:
        """Find paths that lead to the vulnerable package"""
        try:
            with self.driver.session() as session:
                result = session.run("""
                    MATCH path = (r:Repository {url: $repo_url})-[:BELONGS_TO]-(f:File)-[:IMPORTS*1..3]->(m:Module)
                    WHERE m.name CONTAINS $package_name
                    RETURN [node in nodes(path) WHERE node:File | node.path] as file_paths
                    LIMIT 10
                """, repo_url=repo_url, package_name=package_name)
                
                paths = []
                for row in result:
                    paths.append(" -> ".join(row["file_paths"]))
                
                return paths
                
        except Exception as e:
            console.print(f"❌ Failed to find reachable paths: {e}", style="red")
            return []
    
    def _estimate_impact(self, risk_score: float, affected_files: int) -> str:
        """Estimate impact level based on risk score and affected files"""
        if risk_score > 0.8 and affected_files > 10:
            return "critical"
        elif risk_score > 0.6 and affected_files > 5:
            return "high"
        elif risk_score > 0.4 and affected_files > 2:
            return "medium"
        else:
            return "low"
    
    def _generate_remediation_plan(self, vulnerability: VulnerabilityReport) -> RemediationPlan:
        """Generate remediation plan for a vulnerability"""
        console.print(f"🔧 Generating remediation plan for {vulnerability.package_name}...", style="blue")
        
        try:
            # Get current version
            current_version = vulnerability.version_affected
            
            # Find fixed versions
            fixed_versions = vulnerability.fixed_versions or []
            if not fixed_versions:
                # Try to find latest version
                fixed_versions = [self._get_latest_version(vulnerability.package_name)]
            
            recommended_version = fixed_versions[0] if fixed_versions else current_version
            
            # Generate migration steps
            migration_steps = self._generate_migration_steps(
                vulnerability.package_name, current_version, recommended_version
            )
            
            # Generate rollback procedure
            rollback_procedure = self._generate_rollback_procedure(
                vulnerability.package_name, current_version
            )
            
            # Generate testing recommendations
            testing_recommendations = self._generate_testing_recommendations(
                vulnerability.package_name, current_version, recommended_version
            )
            
            # Estimate time
            estimated_time = self._estimate_remediation_time(
                vulnerability.package_name, current_version, recommended_version
            )
            
            # Assess risk level
            risk_level = self._assess_remediation_risk(
                vulnerability.package_name, current_version, recommended_version
            )
            
            return RemediationPlan(
                package_name=vulnerability.package_name,
                current_version=current_version,
                recommended_version=recommended_version,
                breaking_changes=self._identify_breaking_changes(
                    vulnerability.package_name, current_version, recommended_version
                ),
                migration_steps=migration_steps,
                rollback_procedure=rollback_procedure,
                testing_recommendations=testing_recommendations,
                estimated_time=estimated_time,
                risk_level=risk_level
            )
            
        except Exception as e:
            console.print(f"❌ Failed to generate remediation plan: {e}", style="red")
            # Return basic plan
            return RemediationPlan(
                package_name=vulnerability.package_name,
                current_version=vulnerability.version_affected,
                recommended_version=vulnerability.version_affected,
                breaking_changes=[],
                migration_steps=["Update package version"],
                rollback_procedure=["Revert to previous version"],
                testing_recommendations=["Test functionality"],
                estimated_time="1 hour",
                risk_level="medium"
            )
    
    def _get_latest_version(self, package_name: str) -> str:
        """Get the latest version of a package"""
        # This would typically query package registries (npm, PyPI, etc.)
        # For now, return a placeholder
        return "latest"
    
    def _generate_migration_steps(self, package_name: str, from_version: str, to_version: str) -> List[str]:
        """Generate step-by-step migration instructions"""
        return [
            f"1. Update {package_name} from {from_version} to {to_version}",
            f"2. Run tests to ensure compatibility",
            f"3. Check for breaking changes",
            f"4. Update any dependent code if necessary"
        ]
    
    def _generate_rollback_procedure(self, package_name: str, original_version: str) -> List[str]:
        """Generate rollback procedure"""
        return [
            f"1. Revert {package_name} to version {original_version}",
            f"2. Restore any modified configuration files",
            f"3. Run full test suite",
            f"4. Verify system functionality"
        ]
    
    def _generate_testing_recommendations(self, package_name: str, from_version: str, to_version: str) -> List[str]:
        """Generate testing recommendations"""
        return [
            f"Test all functionality that uses {package_name}",
            f"Run integration tests",
            f"Check for performance regressions",
            f"Verify security fixes are effective"
        ]
    
    def _estimate_remediation_time(self, package_name: str, from_version: str, to_version: str) -> str:
        """Estimate time required for remediation"""
        # This would be more sophisticated in practice
        return "2-4 hours"
    
    def _assess_remediation_risk(self, package_name: str, from_version: str, to_version: str) -> str:
        """Assess risk level of remediation"""
        # This would analyze breaking changes and compatibility
        return "medium"
    
    def _identify_breaking_changes(self, package_name: str, from_version: str, to_version: str) -> List[str]:
        """Identify potential breaking changes"""
        # This would query package documentation and changelogs
        return ["Check package changelog for breaking changes"]
    
    def _generate_comprehensive_report(self, 
                                     repo_url: str, 
                                     vulnerabilities: List[VulnerabilityReport],
                                     impact_analyses: List[ImpactAnalysis],
                                     remediation_plans: List[RemediationPlan]) -> Dict[str, Any]:
        """Generate comprehensive vulnerability report"""
        console.print("📋 Generating comprehensive report...", style="blue")
        
        # Calculate summary statistics
        total_vulns = len(vulnerabilities)
        critical_vulns = len([v for v in vulnerabilities if v.severity == "CRITICAL"])
        high_vulns = len([v for v in vulnerabilities if v.severity == "HIGH"])
        medium_vulns = len([v for v in vulnerabilities if v.severity == "MEDIUM"])
        low_vulns = len([v for v in vulnerabilities if v.severity == "LOW"])
        
        # Calculate overall risk score
        overall_risk = sum(analysis.risk_score for analysis in impact_analyses) / len(impact_analyses) if impact_analyses else 0.0
        
        # Generate report
        report = {
            "repository": repo_url,
            "scan_timestamp": datetime.now().isoformat(),
            "summary": {
                "total_vulnerabilities": total_vulns,
                "critical_vulnerabilities": critical_vulns,
                "high_vulnerabilities": high_vulns,
                "medium_vulnerabilities": medium_vulns,
                "low_vulnerabilities": low_vulns,
                "overall_risk_score": overall_risk
            },
            "vulnerabilities": [asdict(v) for v in vulnerabilities],
            "impact_analyses": [asdict(a) for a in impact_analyses],
            "remediation_plans": [asdict(p) for p in remediation_plans],
            "recommendations": self._generate_recommendations(vulnerabilities, impact_analyses)
        }
        
        return report
    
    def _generate_recommendations(self, 
                                vulnerabilities: List[VulnerabilityReport],
                                impact_analyses: List[ImpactAnalysis]) -> List[str]:
        """Generate actionable recommendations"""
        recommendations = []
        
        # Prioritize by severity and impact
        critical_vulns = [v for v in vulnerabilities if v.severity == "CRITICAL"]
        if critical_vulns:
            recommendations.append("🔴 IMMEDIATE ACTION REQUIRED: Address critical vulnerabilities first")
        
        high_impact_vulns = [v for v in vulnerabilities if any(
            a.vulnerable_package == v.package_name and a.estimated_impact in ["high", "critical"]
            for a in impact_analyses
        )]
        if high_impact_vulns:
            recommendations.append("⚠️ HIGH IMPACT: Focus on vulnerabilities affecting many files")
        
        # General recommendations
        if vulnerabilities:
            recommendations.append("📦 Update vulnerable packages to latest secure versions")
            recommendations.append("🧪 Implement comprehensive testing after updates")
            recommendations.append("📋 Review and update security policies")
        
        return recommendations
    
    def display_report(self, report: Dict[str, Any]):
        """Display vulnerability report in a nice format"""
        console.print("\n" + "="*80, style="bold blue")
        console.print("🔒 VULNERABILITY ANALYSIS REPORT", style="bold blue")
        console.print("="*80, style="bold blue")
        
        # Summary
        summary = report["summary"]
        console.print(f"\n📊 SUMMARY:", style="bold")
        console.print(f"   Repository: {report['repository']}")
        console.print(f"   Total Vulnerabilities: {summary['total_vulnerabilities']}")
        console.print(f"   Critical: {summary['critical_vulnerabilities']} | High: {summary['high_vulnerabilities']} | Medium: {summary['medium_vulnerabilities']} | Low: {summary['low_vulnerabilities']}")
        console.print(f"   Overall Risk Score: {summary['overall_risk_score']:.2f}")
        
        # Vulnerabilities table
        if report["vulnerabilities"]:
            console.print(f"\n🚨 VULNERABILITIES:", style="bold")
            table = Table(show_header=True, header_style="bold magenta")
            table.add_column("CVE ID", style="cyan")
            table.add_column("Package", style="green")
            table.add_column("Severity", style="red")
            table.add_column("Confidence", style="yellow")
            
            for vuln in report["vulnerabilities"]:
                severity_color = {
                    "CRITICAL": "red",
                    "HIGH": "orange", 
                    "MEDIUM": "yellow",
                    "LOW": "green"
                }.get(vuln["severity"], "white")
                
                table.add_row(
                    vuln["cve_id"],
                    f"{vuln['package_name']}@{vuln['version_affected']}",
                    f"[{severity_color}]{vuln['severity']}[/{severity_color}]",
                    f"{vuln['confidence_score']:.2f}"
                )
            
            console.print(table)
        
        # Recommendations
        if report["recommendations"]:
            console.print(f"\n💡 RECOMMENDATIONS:", style="bold")
            for rec in report["recommendations"]:
                console.print(f"   • {rec}")
        
        console.print("\n" + "="*80, style="bold blue")
    
    def close(self):
        """Close the Neo4j driver connection"""
        if self.driver:
            self.driver.close()
            console.print("✅ Neo4j connection closed", style="green")


def main():
    """Demo function showing how to use the Vulnerability System"""
    
    # Test repositories
    test_repos = [
        "file://C:\\Projects\\requests",
        "file://C:\\Projects\\openai-python"
    ]
    
    console.print("=== Agentic Vulnerability Analysis and Remediation Demo ===\n", style="bold blue")
    
    try:
        # Initialize vulnerability system
        vuln_system = VulnerabilitySystem()
        
        # Analyze repositories
        for repo_url in test_repos:
            console.print(f"\n🔍 Analyzing repository: {repo_url}", style="bold")
            try:
                report = vuln_system.analyze_repository(repo_url)
                vuln_system.display_report(report)
                
            except Exception as e:
                console.print(f"❌ Failed to analyze {repo_url}: {e}", style="red")
        
        vuln_system.close()
        
    except Exception as e:
        console.print(f"❌ Demo failed: {e}", style="red")
        console.print("Please check your Neo4j connection and try again.", style="yellow")


if __name__ == "__main__":
    main() 