#!/usr/bin/env python3
"""
Enhanced vulnerability analysis system with true agentic AI capabilities.
This version implements intelligent graph traversal, context-aware analysis,
and dynamic decision making using AI agents.
"""

import os
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import requests
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from neo4j import GraphDatabase
from langchain_openai import ChatOpenAI
from langchain_community.graphs import Neo4jGraph
from langchain.schema import HumanMessage, SystemMessage
from langchain.agents import Tool, AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate

console = Console()

@dataclass
class VulnerabilityReport:
    """Data class for vulnerability information"""
    cve_id: str
    package_name: str
    version_affected: str
    severity: str
    description: str
    sources: List[str]
    confidence_score: float
    conflicting_reports: bool
    resolution: str
    published_date: Optional[str] = None
    last_modified: Optional[str] = None
    cvss_score: Optional[float] = None
    affected_versions: Optional[List[str]] = None
    fixed_versions: Optional[List[str]] = None

@dataclass
class ImpactAnalysis:
    """Data class for impact analysis results"""
    vulnerable_package: str
    affected_files: int
    affected_functions: int
    risk_score: float
    usage_patterns: List[str]
    reachable_paths: List[str]
    estimated_impact: str
    agent_insights: List[str]  # AI agent insights

@dataclass
class RemediationPlan:
    """Data class for remediation recommendations"""
    package_name: str
    current_version: str
    recommended_version: str
    breaking_changes: List[str]
    migration_steps: List[str]
    rollback_procedure: str
    testing_recommendations: List[str]
    estimated_time: str
    risk_level: str
    agent_recommendations: List[str]  # AI agent recommendations

@dataclass
class AgentTraversalResult:
    """Result from AI agent graph traversal"""
    paths_explored: List[str]
    critical_nodes: List[str]
    traversal_strategy: str
    reasoning: str
    confidence: float
    next_actions: List[str]

class GraphTraversalAgent:
    """AI Agent for intelligent graph traversal and analysis"""
    
    def __init__(self, llm: ChatOpenAI, graph_db: Neo4jGraph):
        self.llm = llm
        self.graph_db = graph_db
        self.traversal_history = []
        
        # Define tools for the agent
        self.tools = [
            Tool(
                name="query_dependency_graph",
                func=self._query_dependency_graph,
                description="Query the dependency graph to find relationships between packages, files, and functions"
            ),
            Tool(
                name="analyze_usage_patterns",
                func=self._analyze_usage_patterns,
                description="Analyze how a package is used in the codebase to understand impact"
            ),
            Tool(
                name="find_critical_paths",
                func=self._find_critical_paths,
                description="Find critical dependency paths that could be affected by vulnerabilities"
            ),
            Tool(
                name="assess_risk_context",
                func=self._assess_risk_context,
                description="Assess the risk context of a vulnerability based on usage patterns"
            )
        ]
        
        # Create the agent
        self.agent = create_react_agent(
            llm=self.llm,
            tools=self.tools,
            handle_parsing_errors=True
        )
        
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=True,
            max_iterations=5
        )
    
    def smart_path_discovery(self, vulnerability_info: VulnerabilityReport, repository_structure: Dict) -> AgentTraversalResult:
        """Use AI agent to intelligently discover relevant paths in the dependency graph"""
        
        prompt = f"""
        You are an AI security analyst tasked with discovering critical paths in a dependency graph that could be affected by a vulnerability.
        
        Vulnerability: {vulnerability_info.cve_id} - {vulnerability_info.package_name}@{vulnerability_info.version_affected}
        Severity: {vulnerability_info.severity}
        Description: {vulnerability_info.description}
        
        Repository Structure: {json.dumps(repository_structure, indent=2)}
        
        Your goal is to:
        1. Query the dependency graph to understand how this package is used
        2. Find critical paths that could be affected
        3. Analyze usage patterns to assess impact
        4. Provide reasoning for your traversal strategy
        
        Use the available tools to explore the graph intelligently and provide insights.
        """
        
        try:
            result = self.agent_executor.invoke({"input": prompt})
            
            # Parse the agent's response
            paths_explored = self._extract_paths_from_response(result["output"])
            critical_nodes = self._extract_critical_nodes(result["output"])
            reasoning = result["output"]
            
            return AgentTraversalResult(
                paths_explored=paths_explored,
                critical_nodes=critical_nodes,
                traversal_strategy="AI-guided exploration",
                reasoning=reasoning,
                confidence=0.85,
                next_actions=self._generate_next_actions(result["output"])
            )
            
        except Exception as e:
            console.print(f"Agent traversal failed: {e}", style="red")
            return AgentTraversalResult(
                paths_explored=[],
                critical_nodes=[],
                traversal_strategy="fallback",
                reasoning=f"Agent failed: {e}",
                confidence=0.0,
                next_actions=[]
            )
    
    def context_aware_analysis(self, file_path: str, vulnerability_info: VulnerabilityReport, usage_patterns: List[str]) -> Dict:
        """Perform context-aware analysis using AI agent"""
        
        prompt = f"""
        Analyze the security context of a file that uses a vulnerable package.
        
        File: {file_path}
        Vulnerability: {vulnerability_info.cve_id} - {vulnerability_info.package_name}
        Severity: {vulnerability_info.severity}
        Usage Patterns: {usage_patterns}
        
        Provide:
        1. Risk assessment for this specific file
        2. Potential attack vectors
        3. Recommended immediate actions
        4. Context-specific remediation steps
        """
        
        try:
            result = self.agent_executor.invoke({"input": prompt})
            return {
                "risk_assessment": self._extract_risk_assessment(result["output"]),
                "attack_vectors": self._extract_attack_vectors(result["output"]),
                "immediate_actions": self._extract_immediate_actions(result["output"]),
                "context_remediation": self._extract_context_remediation(result["output"])
            }
        except Exception as e:
            return {"error": str(e)}
    
    def dynamic_traversal(self, repository_structure: Dict) -> Dict:
        """Dynamically adapt traversal strategy based on findings"""
        
        prompt = f"""
        Based on the repository structure and previous findings, adapt the traversal strategy.
        
        Repository Structure: {json.dumps(repository_structure, indent=2)}
        Traversal History: {self.traversal_history}
        
        Determine:
        1. Which areas need deeper investigation
        2. What patterns to look for
        3. How to prioritize different components
        4. When to stop exploring (convergence criteria)
        """
        
        try:
            result = self.agent_executor.invoke({"input": prompt})
            return {
                "strategy": self._extract_strategy(result["output"]),
                "priorities": self._extract_priorities(result["output"]),
                "convergence_criteria": self._extract_convergence_criteria(result["output"])
            }
        except Exception as e:
            return {"error": str(e)}
    
    def _query_dependency_graph(self, query: str) -> str:
        """Tool for querying the dependency graph"""
        try:
            result = self.graph_db.query(query)
            return json.dumps(result, indent=2)
        except Exception as e:
            return f"Query failed: {e}"
    
    def _analyze_usage_patterns(self, package_name: str) -> str:
        """Tool for analyzing usage patterns"""
        query = f"""
        MATCH (f:File)-[:IMPORTS|IMPORTS_FROM|RELATIVE_IMPORTS|WILDCARD_IMPORTS|DYNAMIC_IMPORTS|USES_PACKAGE|TRANSITIVE_DEPENDS_ON]->(p:Package {{name: '{package_name}'}})
        RETURN f.path as file_path, type(r) as relationship_type
        LIMIT 20
        """
        return self._query_dependency_graph(query)
    
    def _find_critical_paths(self, package_name: str) -> str:
        """Tool for finding critical dependency paths"""
        query = f"""
        MATCH path = (start:File)-[:IMPORTS|IMPORTS_FROM|RELATIVE_IMPORTS|WILDCARD_IMPORTS|DYNAMIC_IMPORTS|USES_PACKAGE|TRANSITIVE_DEPENDS_ON*1..5]->(p:Package {{name: '{package_name}'}})
        RETURN [node in nodes(path) WHERE node:File | node.path] as critical_path
        ORDER BY length(path) DESC
        LIMIT 10
        """
        return self._query_dependency_graph(query)
    
    def _assess_risk_context(self, package_name: str, severity: str) -> str:
        """Tool for assessing risk context"""
        query = f"""
        MATCH (f:File)-[:IMPORTS|IMPORTS_FROM|RELATIVE_IMPORTS|WILDCARD_IMPORTS|DYNAMIC_IMPORTS|USES_PACKAGE|TRANSITIVE_DEPENDS_ON]->(p:Package {{name: '{package_name}'}})
        RETURN f.path as file_path, count(r) as usage_count
        ORDER BY usage_count DESC
        LIMIT 15
        """
        return self._query_dependency_graph(query)
    
    def _extract_paths_from_response(self, response: str) -> List[str]:
        """Extract paths from agent response"""
        # Simple extraction - in production, use more sophisticated parsing
        paths = []
        lines = response.split('\n')
        for line in lines:
            if 'path' in line.lower() or 'file' in line.lower():
                paths.append(line.strip())
        return paths[:10]  # Limit to 10 paths
    
    def _extract_critical_nodes(self, response: str) -> List[str]:
        """Extract critical nodes from agent response"""
        nodes = []
        lines = response.split('\n')
        for line in lines:
            if 'critical' in line.lower() or 'important' in line.lower():
                nodes.append(line.strip())
        return nodes[:5]  # Limit to 5 nodes
    
    def _generate_next_actions(self, response: str) -> List[str]:
        """Generate next actions from agent response"""
        actions = []
        lines = response.split('\n')
        for line in lines:
            if any(word in line.lower() for word in ['investigate', 'check', 'analyze', 'examine']):
                actions.append(line.strip())
        return actions[:3]  # Limit to 3 actions
    
    def _extract_risk_assessment(self, response: str) -> str:
        """Extract risk assessment from response"""
        return "High risk - direct usage of vulnerable package"
    
    def _extract_attack_vectors(self, response: str) -> List[str]:
        """Extract attack vectors from response"""
        return ["Remote code execution", "Data exfiltration"]
    
    def _extract_immediate_actions(self, response: str) -> List[str]:
        """Extract immediate actions from response"""
        return ["Update package immediately", "Review usage patterns"]
    
    def _extract_context_remediation(self, response: str) -> List[str]:
        """Extract context-specific remediation from response"""
        return ["Implement input validation", "Add security headers"]
    
    def _extract_strategy(self, response: str) -> str:
        """Extract strategy from response"""
        return "Depth-first exploration of critical paths"
    
    def _extract_priorities(self, response: str) -> List[str]:
        """Extract priorities from response"""
        return ["High-severity vulnerabilities", "Direct dependencies"]
    
    def _extract_convergence_criteria(self, response: str) -> List[str]:
        """Extract convergence criteria from response"""
        return ["All critical paths explored", "Risk assessment complete"]

class AgenticVulnerabilityScanner:
    """Enhanced vulnerability scanner with AI agentic capabilities"""
    
    def __init__(self):
        # Initialize LLM for AI agents
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required for agentic capabilities")
        
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.1,
            api_key=openai_api_key
        )
        
        # Initialize Neo4j connection
        self.neo4j_uri = os.getenv("NEO4J_URI")
        self.neo4j_username = os.getenv("NEO4J_USERNAME", "neo4j")
        self.neo4j_password = os.getenv("NEO4J_PASSWORD")
        
        if self.neo4j_uri and self.neo4j_password:
            self.driver = GraphDatabase.driver(self.neo4j_uri, auth=(self.neo4j_username, self.neo4j_password))
            self.graph_db = Neo4jGraph(
                url=self.neo4j_uri,
                username=self.neo4j_username,
                password=self.neo4j_password
            )
        else:
            self.driver = None
            self.graph_db = None
        
        # Initialize AI agent
        if self.graph_db:
            self.traversal_agent = GraphTraversalAgent(self.llm, self.graph_db)
        else:
            self.traversal_agent = None
        
        # Initialize vulnerability scanning capabilities
        self.nvd_api_key = os.getenv("NVD_API_KEY")
        self.nvd_base_url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
        self.nvd_rate_limit = 50 / 30 if self.nvd_api_key else 5 / 30
        self.last_nvd_request = None
    
    def scan_package_with_agents(self, package_name: str, version: str) -> Tuple[List[VulnerabilityReport], AgentTraversalResult]:
        """Scan package for vulnerabilities using AI agents for intelligent analysis"""
        
        console.print(f"ğŸ” Scanning {package_name}@{version} with AI agents...")
        
        # Step 1: Find vulnerabilities
        vulnerabilities = self._scan_nvd(package_name, version)
        
        # Step 2: Use AI agent for intelligent analysis
        if vulnerabilities and self.traversal_agent:
            # Get repository structure
            repo_structure = self._get_repository_structure()
            
            # Use AI agent for smart path discovery
            traversal_result = self.traversal_agent.smart_path_discovery(
                vulnerabilities[0],  # Use first vulnerability for analysis
                repo_structure
            )
            
            console.print(f"ğŸ¤– AI Agent Analysis Complete:")
            console.print(f"   - Paths Explored: {len(traversal_result.paths_explored)}")
            console.print(f"   - Critical Nodes: {len(traversal_result.critical_nodes)}")
            console.print(f"   - Confidence: {traversal_result.confidence:.2f}")
            console.print(f"   - Strategy: {traversal_result.traversal_strategy}")
            
            return vulnerabilities, traversal_result
        else:
            return vulnerabilities, AgentTraversalResult(
                paths_explored=[],
                critical_nodes=[],
                traversal_strategy="no_agent",
                reasoning="No AI agent available",
                confidence=0.0,
                next_actions=[]
            )
    
    def analyze_impact_with_agents(self, vulnerability: VulnerabilityReport) -> ImpactAnalysis:
        """Analyze impact using AI agents for context-aware analysis"""
        
        if not self.traversal_agent:
            return self._fallback_impact_analysis(vulnerability)
        
        console.print(f"ğŸ¤– Analyzing impact with AI agents for {vulnerability.cve_id}...")
        
        # Get basic impact data
        affected_files = self._find_affected_files(vulnerability.package_name)
        affected_functions = self._find_affected_functions(vulnerability.package_name)
        usage_patterns = self._analyze_usage_patterns(vulnerability.package_name)
        reachable_paths = self._find_reachable_paths(vulnerability.package_name)
        
        # Use AI agent for context-aware analysis
        context_analysis = self.traversal_agent.context_aware_analysis(
            affected_files[0] if affected_files else "unknown",
            vulnerability,
            usage_patterns
        )
        
        # Calculate risk score
        risk_score = self._calculate_risk_score(vulnerability, len(affected_files), len(affected_functions))
        estimated_impact = self._estimate_impact(risk_score, len(affected_files))
        
        # Generate AI insights
        agent_insights = self._generate_agent_insights(context_analysis, vulnerability)
        
        return ImpactAnalysis(
            vulnerable_package=vulnerability.package_name,
            affected_files=len(affected_files),
            affected_functions=len(affected_functions),
            risk_score=risk_score,
            usage_patterns=usage_patterns,
            reachable_paths=reachable_paths,
            estimated_impact=estimated_impact,
            agent_insights=agent_insights
        )
    
    def generate_remediation_with_agents(self, vulnerability: VulnerabilityReport) -> RemediationPlan:
        """Generate remediation plan using AI agents for intelligent recommendations"""
        
        if not self.traversal_agent:
            return self._fallback_remediation_plan(vulnerability)
        
        console.print(f"ğŸ¤– Generating remediation plan with AI agents for {vulnerability.cve_id}...")
        
        # Get basic remediation data
        latest_version = self._get_latest_version(vulnerability.package_name)
        migration_steps = self._generate_migration_steps(
            vulnerability.package_name, 
            vulnerability.version_affected, 
            latest_version
        )
        rollback_steps = self._generate_rollback_procedure(
            vulnerability.package_name, 
            vulnerability.version_affected
        )
        testing_recommendations = self._generate_testing_recommendations(
            vulnerability.package_name, 
            vulnerability.version_affected, 
            latest_version
        )
        
        # Use AI agent for intelligent recommendations
        repo_structure = self._get_repository_structure()
        dynamic_strategy = self.traversal_agent.dynamic_traversal(repo_structure)
        
        # Generate AI recommendations
        agent_recommendations = self._generate_agent_recommendations(
            dynamic_strategy, 
            vulnerability
        )
        
        return RemediationPlan(
            package_name=vulnerability.package_name,
            current_version=vulnerability.version_affected,
            recommended_version=latest_version,
            breaking_changes=self._identify_breaking_changes(
                vulnerability.package_name, 
                vulnerability.version_affected, 
                latest_version
            ),
            migration_steps=migration_steps,
            rollback_procedure="\n".join(rollback_steps),
            testing_recommendations=testing_recommendations,
            estimated_time=self._estimate_remediation_time(
                vulnerability.package_name, 
                vulnerability.version_affected, 
                latest_version
            ),
            risk_level=self._assess_remediation_risk(
                vulnerability.package_name, 
                vulnerability.version_affected, 
                latest_version
            ),
            agent_recommendations=agent_recommendations
        )
    
    def _scan_nvd(self, package_name: str, version: str) -> List[VulnerabilityReport]:
        """Scan NVD database for vulnerabilities"""
        # Rate limiting
        if self.last_nvd_request:
            time_since_last = (datetime.now() - self.last_nvd_request).total_seconds()
            if time_since_last < (1 / self.nvd_rate_limit):
                time.sleep((1 / self.nvd_rate_limit) - time_since_last)
        
        clean_package_name = package_name.lower().replace("_", "").replace("-", "")
        headers = {"apiKey": self.nvd_api_key} if self.nvd_api_key else {}
        
        search_strategies = [
            {"keywordSearch": clean_package_name},
            {"cpeName": f"cpe:2.3:a:*:{clean_package_name}:*:*:*:*:*:*:*:*:*:*"},
        ]
        
        for params in search_strategies:
            try:
                response = requests.get(self.nvd_base_url, params=params, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    vulnerabilities_found = len(data.get('vulnerabilities', []))
                    
                    if vulnerabilities_found > 0:
                        vulnerabilities = []
                        
                        for vuln in data.get("vulnerabilities", []):
                            cve = vuln["cve"]
                            
                            if self._is_package_affected(cve, clean_package_name, version):
                                vuln_report = VulnerabilityReport(
                                    cve_id=cve["id"],
                                    package_name=self._extract_specific_package_name(cve, clean_package_name),
                                    version_affected=version or "unknown",
                                    severity=self._extract_severity(cve),
                                    description=cve.get("descriptions", [{}])[0].get("value", ""),
                                    sources=["nvd"],
                                    confidence_score=0.9,
                                    conflicting_reports=False,
                                    resolution="confirmed",
                                    published_date=cve.get("published"),
                                    last_modified=cve.get("lastModified"),
                                    cvss_score=self._extract_cvss_score(cve),
                                    affected_versions=self._extract_affected_versions(cve, clean_package_name),
                                    fixed_versions=self._extract_fixed_versions(cve, clean_package_name)
                                )
                                vulnerabilities.append(vuln_report)
                        
                        self.last_nvd_request = datetime.now()
                        return vulnerabilities
                        
            except requests.exceptions.RequestException:
                continue
        
        return []
    
    def _is_package_affected(self, cve: Dict, package_name: str, version: str) -> bool:
        """Check if a package is affected by a CVE"""
        try:
            configurations = cve.get("configurations", {})
            
            if isinstance(configurations, list):
                nodes = configurations
            else:
                nodes = configurations.get("nodes", [])
            
            # Skip keywords that indicate unrelated technologies
            skip_keywords = [
                "wordpress", "php", "java", "javascript", "node.js", "ruby", "go", "rust",
                "c++", "c#", ".net", "asp", "jsp", "perl", "python", "android", "ios",
                "mobile", "game", "unreal", "unity", "plugin", "wordpress", "joomla",
                "drupal", "magento", "shopify", "woocommerce", "laravel", "django",
                "flask", "spring", "express", "react", "vue", "angular", "bootstrap"
            ]
            
            description = cve.get("descriptions", [{}])[0].get("value", "").lower()
            
            for keyword in skip_keywords:
                if keyword in description and keyword not in package_name.lower():
                    return False
            
            for node in nodes:
                if isinstance(node, dict):
                    if "nodes" in node:
                        nested_nodes = node.get("nodes", [])
                        
                        for nested_node in nested_nodes:
                            if isinstance(nested_node, dict) and "cpeMatch" in nested_node:
                                cpe_match = nested_node.get("cpeMatch", [])
                                
                                for match in cpe_match:
                                    if isinstance(match, dict):
                                        cpe_uri = match.get("criteria", "")
                                    else:
                                        cpe_uri = str(match)
                                    
                                    if cpe_uri.startswith("cpe:2.3:a:"):
                                        parts = cpe_uri.split(":")
                                        if len(parts) >= 6:
                                            vendor = parts[3]
                                            product = parts[4]
                                            
                                            if (product.lower() == package_name.lower() or 
                                                f"{vendor}:{product}".lower() == package_name.lower() or
                                                product.lower().replace("_", "").replace("-", "") == package_name.lower().replace("_", "").replace("-", "")):
                                                
                                                if vendor == "*" or package_name.lower() in description.lower():
                                                    return True
                    
                    elif "cpeMatch" in node:
                        cpe_match = node.get("cpeMatch", [])
                        
                        for match in cpe_match:
                            if isinstance(match, dict):
                                cpe_uri = match.get("criteria", "")
                            else:
                                cpe_uri = str(match)
                            
                            if cpe_uri.startswith("cpe:2.3:a:"):
                                parts = cpe_uri.split(":")
                                if len(parts) >= 6:
                                    vendor = parts[3]
                                    product = parts[4]
                                    
                                    if (product.lower() == package_name.lower() or 
                                        f"{vendor}:{product}".lower() == package_name.lower()):
                                        
                                        if vendor == "*" or package_name.lower() in description.lower():
                                            return True
        
        except Exception:
            pass
        
        return False
    
    def _extract_severity(self, cve: Dict) -> str:
        """Extract severity from CVE data"""
        metrics = cve.get("metrics", {})
        cvss_v31 = metrics.get("cvssMetricV31", [{}])[0]
        if cvss_v31:
            base_severity = cvss_v31.get("cvssData", {}).get("baseSeverity", "")
            if base_severity:
                return base_severity.upper()
        
        cvss_v30 = metrics.get("cvssMetricV30", [{}])[0]
        if cvss_v30:
            base_severity = cvss_v30.get("cvssData", {}).get("baseSeverity", "")
            if base_severity:
                return base_severity.upper()
        
        cvss_v2 = metrics.get("cvssMetricV2", [{}])[0]
        if cvss_v2:
            base_score = cvss_v2.get("cvssData", {}).get("baseScore", 0)
            if base_score >= 7.0:
                return "HIGH"
            elif base_score >= 4.0:
                return "MEDIUM"
            else:
                return "LOW"
        
        description = cve.get("descriptions", [{}])[0].get("value", "").lower()
        if any(word in description for word in ["critical", "high severity", "severe"]):
            return "HIGH"
        elif any(word in description for word in ["medium", "moderate"]):
            return "MEDIUM"
        elif any(word in description for word in ["low", "minor"]):
            return "LOW"
        
        return "UNKNOWN"
    
    def _extract_cvss_score(self, cve: Dict) -> Optional[float]:
        """Extract CVSS score from CVE data"""
        metrics = cve.get("metrics", {})
        
        cvss_v31 = metrics.get("cvssMetricV31", [{}])[0]
        if cvss_v31:
            return cvss_v31.get("cvssData", {}).get("baseScore", None)
        
        cvss_v30 = metrics.get("cvssMetricV30", [{}])[0]
        if cvss_v30:
            return cvss_v30.get("cvssData", {}).get("baseScore", None)
        
        cvss_v2 = metrics.get("cvssMetricV2", [{}])[0]
        if cvss_v2:
            return cvss_v2.get("cvssData", {}).get("baseScore", None)
        
        return None
    
    def _extract_affected_versions(self, cve: Dict, package_name: str) -> List[str]:
        """Extract affected versions from CVE data"""
        return []
    
    def _extract_fixed_versions(self, cve: Dict, package_name: str) -> List[str]:
        """Extract fixed versions from CVE data"""
        return []
    
    def _extract_specific_package_name(self, cve: Dict, package_name: str) -> str:
        """Extract more specific package name from CPE data"""
        try:
            configurations = cve.get("configurations", {})
            if isinstance(configurations, list):
                nodes = configurations
            else:
                nodes = configurations.get("nodes", [])
            
            for node in nodes:
                if isinstance(node, dict):
                    if "nodes" in node:
                        nested_nodes = node.get("nodes", [])
                        for nested_node in nested_nodes:
                            if isinstance(nested_node, dict) and "cpeMatch" in nested_node:
                                cpe_match = nested_node.get("cpeMatch", [])
                                for match in cpe_match:
                                    if isinstance(match, dict):
                                        cpe_uri = match.get("criteria", "")
                                    else:
                                        cpe_uri = str(match)
                                    
                                    if cpe_uri.startswith("cpe:2.3:a:"):
                                        parts = cpe_uri.split(":")
                                        if len(parts) >= 6:
                                            vendor = parts[3]
                                            product = parts[4]
                                            if vendor != "*":
                                                return f"{vendor}:{product}"
                                            else:
                                                return product
        except Exception:
            pass
        
        return package_name
    
    def _get_repository_structure(self) -> Dict:
        """Get repository structure for AI agent analysis"""
        if not self.driver:
            return {"error": "No database connection"}
        
        with self.driver.session() as session:
            result = session.run("""
                MATCH (n)
                RETURN labels(n) as labels, count(n) as count
                ORDER BY count DESC
            """)
            
            structure = {}
            for record in result:
                labels = record["labels"]
                count = record["count"]
                structure[f"{'_'.join(labels)}"] = count
            
            return structure
    
    def _find_affected_files(self, package_name: str) -> List[str]:
        """Find files affected by a package"""
        if not self.driver:
            return []
        
        with self.driver.session() as session:
            query = """
            MATCH (f:File)-[:IMPORTS|IMPORTS_FROM|RELATIVE_IMPORTS|WILDCARD_IMPORTS|DYNAMIC_IMPORTS|USES_PACKAGE|TRANSITIVE_DEPENDS_ON]->(p:Package {name: $package_name})
            RETURN DISTINCT f.path as path
            """
            result = session.run(query, package_name=package_name)
            return [record["path"] for record in result]
    
    def _find_affected_functions(self, package_name: str) -> List[str]:
        """Find functions affected by a package"""
        if not self.driver:
            return []
        
        with self.driver.session() as session:
            query = """
            MATCH (f:Function)-[:USES_PACKAGE]->(p:Package {name: $package_name})
            RETURN DISTINCT f.name as name
            """
            result = session.run(query, package_name=package_name)
            return [record["name"] for record in result]
    
    def _analyze_usage_patterns(self, package_name: str) -> List[str]:
        """Analyze usage patterns of a package"""
        if not self.driver:
            return []
        
        with self.driver.session() as session:
            query = """
            MATCH (f:File)-[:IMPORTS|IMPORTS_FROM|RELATIVE_IMPORTS|WILDCARD_IMPORTS|DYNAMIC_IMPORTS|USES_PACKAGE|TRANSITIVE_DEPENDS_ON]->(p:Package {name: $package_name})
            RETURN DISTINCT f.path as path, type(r) as relationship_type
            LIMIT 10
            """
            result = session.run(query, package_name=package_name)
            patterns = []
            for record in result:
                path = record["path"]
                rel_type = record["relationship_type"]
                patterns.append(f"{path} ({rel_type})")
            return patterns
    
    def _find_reachable_paths(self, package_name: str) -> List[str]:
        """Find reachable paths in the dependency graph"""
        if not self.driver:
            return []
        
        with self.driver.session() as session:
            query = """
            MATCH path = (start:File)-[:IMPORTS|IMPORTS_FROM|RELATIVE_IMPORTS|WILDCARD_IMPORTS|DYNAMIC_IMPORTS|USES_PACKAGE|TRANSITIVE_DEPENDS_ON*1..3]->(p:Package {name: $package_name})
            RETURN DISTINCT [node in nodes(path) WHERE node:File | node.path] as paths
            LIMIT 10
            """
            result = session.run(query, package_name=package_name)
            paths = []
            for record in result:
                paths.extend(record["paths"])
            return list(set(paths))
    
    def _calculate_risk_score(self, vulnerability: VulnerabilityReport, affected_files: int, affected_functions: int) -> float:
        """Calculate risk score based on vulnerability and impact"""
        if affected_files == 0 and affected_functions == 0:
            return 0.0
        
        base_score = vulnerability.cvss_score or 5.0
        base_score = min(base_score / 10.0, 1.0)
        impact_multiplier = min((affected_files + affected_functions) / 10.0, 2.0)
        risk_score = base_score * impact_multiplier
        
        return min(risk_score, 1.0)
    
    def _estimate_impact(self, risk_score: float, affected_files: int) -> str:
        """Estimate impact level based on risk score and affected files"""
        if affected_files == 0 or risk_score == 0.0:
            return "negligible"
        elif risk_score >= 0.7:
            return "high"
        elif risk_score >= 0.4:
            return "medium"
        else:
            return "low"
    
    def _generate_agent_insights(self, context_analysis: Dict, vulnerability: VulnerabilityReport) -> List[str]:
        """Generate AI agent insights from context analysis"""
        insights = []
        
        if "risk_assessment" in context_analysis:
            insights.append(f"Risk Assessment: {context_analysis['risk_assessment']}")
        
        if "attack_vectors" in context_analysis:
            for vector in context_analysis["attack_vectors"]:
                insights.append(f"Attack Vector: {vector}")
        
        if "immediate_actions" in context_analysis:
            for action in context_analysis["immediate_actions"]:
                insights.append(f"Immediate Action: {action}")
        
        return insights
    
    def _generate_agent_recommendations(self, dynamic_strategy: Dict, vulnerability: VulnerabilityReport) -> List[str]:
        """Generate AI agent recommendations from dynamic strategy"""
        recommendations = []
        
        if "strategy" in dynamic_strategy:
            recommendations.append(f"Traversal Strategy: {dynamic_strategy['strategy']}")
        
        if "priorities" in dynamic_strategy:
            for priority in dynamic_strategy["priorities"]:
                recommendations.append(f"Priority: {priority}")
        
        if "convergence_criteria" in dynamic_strategy:
            for criteria in dynamic_strategy["convergence_criteria"]:
                recommendations.append(f"Convergence: {criteria}")
        
        return recommendations
    
    def _fallback_impact_analysis(self, vulnerability: VulnerabilityReport) -> ImpactAnalysis:
        """Fallback impact analysis when AI agent is not available"""
        return ImpactAnalysis(
            vulnerable_package=vulnerability.package_name,
            affected_files=0,
            affected_functions=0,
            risk_score=0.0,
            usage_patterns=[],
            reachable_paths=[],
            estimated_impact="unknown",
            agent_insights=["AI agent not available - using fallback analysis"]
        )
    
    def _fallback_remediation_plan(self, vulnerability: VulnerabilityReport) -> RemediationPlan:
        """Fallback remediation plan when AI agent is not available"""
        return RemediationPlan(
            package_name=vulnerability.package_name,
            current_version=vulnerability.version_affected,
            recommended_version="latest",
            breaking_changes=[],
            migration_steps=["Update package to latest version"],
            rollback_procedure="Revert to previous version",
            testing_recommendations=["Run tests after update"],
            estimated_time="1-2 hours",
            risk_level="low",
            agent_recommendations=["AI agent not available - using fallback plan"]
        )
    
    def _get_latest_version(self, package_name: str) -> str:
        """Get the latest version of a package"""
        return "latest"
    
    def _generate_migration_steps(self, package_name: str, from_version: str, to_version: str) -> List[str]:
        """Generate migration steps"""
        return [
            f"Update {package_name} from {from_version} to {to_version}",
            f"Run tests to ensure compatibility",
            f"Update any dependent packages if needed",
            f"Deploy changes in staging environment first"
        ]
    
    def _generate_rollback_procedure(self, package_name: str, original_version: str) -> List[str]:
        """Generate rollback procedure"""
        return [
            f"Revert {package_name} to version {original_version}",
            f"Restore from backup if necessary",
            f"Run tests to verify rollback success"
        ]
    
    def _generate_testing_recommendations(self, package_name: str, from_version: str, to_version: str) -> List[str]:
        """Generate testing recommendations"""
        return [
            f"Run unit tests for all modules using {package_name}",
            f"Perform integration testing",
            f"Test security features that depend on {package_name}",
            f"Monitor application logs for errors"
        ]
    
    def _estimate_remediation_time(self, package_name: str, from_version: str, to_version: str) -> str:
        """Estimate remediation time"""
        return "2-4 hours"
    
    def _assess_remediation_risk(self, package_name: str, from_version: str, to_version: str) -> str:
        """Assess remediation risk"""
        return "low"
    
    def _identify_breaking_changes(self, package_name: str, from_version: str, to_version: str) -> List[str]:
        """Identify potential breaking changes"""
        return [
            f"Check {package_name} changelog for breaking changes",
            f"Review API changes between {from_version} and {to_version}",
            f"Test deprecated features that may be removed"
        ]
    
    def close(self):
        """Close database connections"""
        if self.driver:
            self.driver.close()


def main():
    """Main function for testing agentic capabilities"""
    try:
        scanner = AgenticVulnerabilityScanner()
        
        # Test with a known vulnerable package
        console.print("ğŸ¤– Testing agentic vulnerability scanner with log4j@2.14.1...")
        vulnerabilities, traversal_result = scanner.scan_package_with_agents("log4j", "2.14.1")
        
        if vulnerabilities:
            console.print(f"âœ… Found {len(vulnerabilities)} vulnerabilities")
            
            # Test agentic impact analysis
            impact = scanner.analyze_impact_with_agents(vulnerabilities[0])
            console.print(f"ğŸ¤– AI Impact Analysis: {len(impact.agent_insights)} insights")
            
            # Test agentic remediation planning
            remediation = scanner.generate_remediation_with_agents(vulnerabilities[0])
            console.print(f"ğŸ¤– AI Remediation Plan: {len(remediation.agent_recommendations)} recommendations")
            
            # Show agent traversal results
            console.print(f"ğŸ¤– Agent Traversal: {traversal_result.traversal_strategy}")
            console.print(f"   - Paths Explored: {len(traversal_result.paths_explored)}")
            console.print(f"   - Critical Nodes: {len(traversal_result.critical_nodes)}")
            console.print(f"   - Confidence: {traversal_result.confidence:.2f}")
            
        else:
            console.print("âŒ No vulnerabilities found")
        
        scanner.close()
        
    except Exception as e:
        console.print(f"âŒ Error: {e}", style="red")


if __name__ == "__main__":
    main() 