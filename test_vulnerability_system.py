#!/usr/bin/env python3
"""
Test suite for the vulnerability analysis system.

This module tests the complete vulnerability analysis and remediation workflow
to ensure the system returns valid vulnerability analysis results.
"""

import os
import json
import tempfile
import shutil
from pathlib import Path
from typing import Dict, List, Any
from unittest import TestCase, main
from dataclasses import dataclass

# Import our vulnerability system
from vulnerability_system import VulnerabilityScanner, VulnerabilityReport, ImpactAnalysis, RemediationPlan


@dataclass
class TestResult:
    """Test result data structure."""
    test_name: str
    passed: bool
    message: str
    details: Dict[str, Any] = None


class TestVulnerabilitySystem(TestCase):
    """Test suite for the vulnerability analysis system."""
    
    def setUp(self):
        """Set up test environment."""
        self.scanner = VulnerabilityScanner()
        self.test_results: List[TestResult] = []
        
        # Test data for known vulnerable packages
        self.known_vulnerable_packages = [
            ("log4j", "2.14.1"),  # Known to have multiple CVEs
            ("spring-core", "5.3.0"),  # Spring4Shell vulnerability
            ("jackson-databind", "2.13.0"),  # Known vulnerabilities
            ("fastapi", "0.65.1"),  # CVE-2021-32677 (CSRF vulnerability)
            ("starlette", "0.39.0"),  # CVE-2024-47874 (Memory exhaustion)
        ]
        
        # Test data for clean packages
        self.clean_packages = [
            ("requests", "2.31.0"),  # Should be clean
            ("urllib3", "2.0.0"),  # Should be clean
        ]
        
        # Create temporary directory for test reports
        self.temp_dir = tempfile.mkdtemp()
        
    def tearDown(self):
        """Clean up test environment."""
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
    
    def test_1_known_vulnerable_package_detection(self):
        """Test 1: Verify the system can detect vulnerabilities in known vulnerable packages."""
        print("\n" + "="*60)
        print("TEST 1: Known Vulnerable Package Detection")
        print("="*60)
        
        for package_name, version in self.known_vulnerable_packages:
            print(f"\nTesting package: {package_name}@{version}")
            
            try:
                # Scan the package for vulnerabilities
                vulnerabilities = self.scanner.scan_package(package_name, version)
                
                # Validate results
                if vulnerabilities:
                    print(f"✅ Found {len(vulnerabilities)} vulnerabilities for {package_name}@{version}")
                    
                    # Check that vulnerabilities have required fields
                    for vuln in vulnerabilities:
                        self.assertIsInstance(vuln, VulnerabilityReport)
                        self.assertIsNotNone(vuln.cve_id)
                        self.assertIsNotNone(vuln.severity)
                        self.assertIsNotNone(vuln.description)
                        
                        print(f"  - {vuln.cve_id}: {vuln.severity} - {vuln.description[:100]}...")
                    
                    # For log4j, we expect multiple vulnerabilities
                    if package_name == "log4j" and version == "2.14.1":
                        self.assertGreater(len(vulnerabilities), 5, 
                                         f"Expected at least 5 vulnerabilities for log4j@{version}, found {len(vulnerabilities)}")
                
                else:
                    print(f"⚠️  No vulnerabilities found for {package_name}@{version}")
                    # This might be acceptable if the package was patched
                
            except Exception as e:
                print(f"❌ Error testing {package_name}@{version}: {e}")
                self.fail(f"Failed to test {package_name}@{version}: {e}")
        
        print("\n✅ Test 1 completed: Known vulnerable package detection")
    
    def test_1b_fastapi_specific_vulnerabilities(self):
        """Test 1b: Verify the system can detect specific FastAPI vulnerabilities."""
        print("\n" + "="*60)
        print("TEST 1b: FastAPI Specific Vulnerabilities")
        print("="*60)
        
        # Test FastAPI with known vulnerable version
        package_name, version = "fastapi", "0.65.1"
        print(f"\nTesting FastAPI vulnerabilities: {package_name}@{version}")
        
        try:
            # Scan the package for vulnerabilities
            vulnerabilities = self.scanner.scan_package(package_name, version)
            
            if vulnerabilities:
                print(f"✅ Found {len(vulnerabilities)} vulnerabilities for {package_name}@{version}")
                
                # Look for specific FastAPI vulnerabilities
                fastapi_vulns = []
                for vuln in vulnerabilities:
                    if "fastapi" in vuln.description.lower() or "csrf" in vuln.description.lower():
                        fastapi_vulns.append(vuln)
                        print(f"  - {vuln.cve_id}: {vuln.severity} - {vuln.description[:100]}...")
                
                # We should find at least some FastAPI-related vulnerabilities
                if fastapi_vulns:
                    print(f"✅ Found {len(fastapi_vulns)} FastAPI-specific vulnerabilities")
                else:
                    print("⚠️  No FastAPI-specific vulnerabilities found (may be filtered out)")
                
            else:
                print(f"⚠️  No vulnerabilities found for {package_name}@{version}")
                
        except Exception as e:
            print(f"❌ Error testing FastAPI vulnerabilities: {e}")
            self.fail(f"Failed to test FastAPI vulnerabilities: {e}")
        
        print("\n✅ Test 1b completed: FastAPI specific vulnerabilities")
    
    def test_2_false_positive_filtering(self):
        """Test 2: Verify the system correctly filters out false positives."""
        print("\n" + "="*60)
        print("TEST 2: False Positive Filtering")
        print("="*60)
        
        for package_name, version in self.clean_packages:
            print(f"\nTesting clean package: {package_name}@{version}")
            
            try:
                # Scan the package for vulnerabilities
                vulnerabilities = self.scanner.scan_package(package_name, version)
                
                # For clean packages, we expect few or no vulnerabilities
                if vulnerabilities:
                    print(f"⚠️  Found {len(vulnerabilities)} potential vulnerabilities for {package_name}@{version}")
                    
                    # Check that any found vulnerabilities are actually relevant
                    for vuln in vulnerabilities:
                        # Verify the vulnerability is actually related to the package
                        self.assertIn(package_name.lower(), vuln.package_name.lower() or "",
                                    f"Vulnerability {vuln.cve_id} doesn't match package {package_name}")
                        
                        print(f"  - {vuln.cve_id}: {vuln.severity} - {vuln.description[:100]}...")
                else:
                    print(f"✅ No vulnerabilities found for {package_name}@{version} (expected)")
                
            except Exception as e:
                print(f"❌ Error testing {package_name}@{version}: {e}")
                self.fail(f"Failed to test {package_name}@{version}: {e}")
        
        print("\n✅ Test 2 completed: False positive filtering")
    
    def test_3_impact_analysis_accuracy(self):
        """Test 3: Verify the impact analysis correctly identifies affected files and calculates risk scores."""
        print("\n" + "="*60)
        print("TEST 3: Impact Analysis Accuracy")
        print("="*60)
        
        # Test with a known vulnerable package
        package_name, version = "log4j", "2.14.1"
        print(f"\nTesting impact analysis for: {package_name}@{version}")
        
        try:
            # Scan the package for vulnerabilities
            vulnerabilities = self.scanner.scan_package(package_name, version)
            
            if vulnerabilities:
                # Test impact analysis for the first vulnerability
                vuln = vulnerabilities[0]
                print(f"Testing impact analysis for {vuln.cve_id}")
                
                # Perform impact analysis
                impact = self.scanner.analyze_impact(vuln)
                
                # Validate impact analysis results
                self.assertIsInstance(impact, ImpactAnalysis)
                self.assertIsInstance(impact.affected_files, int)
                self.assertIsInstance(impact.affected_functions, int)
                self.assertIsInstance(impact.risk_score, float)
                self.assertIsInstance(impact.estimated_impact, str)
                
                print(f"  - Affected Files: {impact.affected_files}")
                print(f"  - Affected Functions: {impact.affected_functions}")
                print(f"  - Risk Score: {impact.risk_score:.2f}/1.0")
                print(f"  - Estimated Impact: {impact.estimated_impact}")
                
                # Validate risk score is within expected range
                self.assertGreaterEqual(impact.risk_score, 0.0)
                self.assertLessEqual(impact.risk_score, 1.0)
                
                # If we have affected files, risk score should be > 0
                if impact.affected_files > 0:
                    self.assertGreater(impact.risk_score, 0.0,
                                     "Risk score should be > 0 when there are affected files")
                
            else:
                print(f"⚠️  No vulnerabilities found for {package_name}@{version}, skipping impact analysis")
                
        except Exception as e:
            print(f"❌ Error testing impact analysis: {e}")
            self.fail(f"Failed to test impact analysis: {e}")
        
        print("\n✅ Test 3 completed: Impact analysis accuracy")
    
    def test_4_remediation_plan_generation(self):
        """Test 4: Verify the system generates comprehensive remediation plans."""
        print("\n" + "="*60)
        print("TEST 4: Remediation Plan Generation")
        print("="*60)
        
        # Test with a known vulnerable package
        package_name, version = "log4j", "2.14.1"
        print(f"\nTesting remediation plan generation for: {package_name}@{version}")
        
        try:
            # Scan the package for vulnerabilities
            vulnerabilities = self.scanner.scan_package(package_name, version)
            
            if vulnerabilities:
                # Test remediation planning for the first vulnerability
                vuln = vulnerabilities[0]
                print(f"Testing remediation planning for {vuln.cve_id}")
                
                # Generate remediation plan
                remediation = self.scanner.generate_remediation_plan(vuln)
                
                # Validate remediation plan
                self.assertIsInstance(remediation, RemediationPlan)
                self.assertIsInstance(remediation.migration_steps, list)
                self.assertIsInstance(remediation.rollback_procedure, str)
                self.assertIsInstance(remediation.testing_recommendations, list)
                self.assertIsInstance(remediation.estimated_effort, str)
                
                print(f"  - Migration Steps: {len(remediation.migration_steps)} steps")
                print(f"  - Rollback Procedure: {len(remediation.rollback_procedure)} characters")
                print(f"  - Testing Recommendations: {len(remediation.testing_recommendations)} items")
                print(f"  - Estimated Effort: {remediation.estimated_effort}")
                
                # Validate migration steps are not empty
                self.assertGreater(len(remediation.migration_steps), 0,
                                 "Remediation plan should have at least one migration step")
                
                # Validate rollback procedure is not empty
                self.assertGreater(len(remediation.rollback_procedure), 0,
                                 "Remediation plan should have a rollback procedure")
                
                # Validate testing recommendations are not empty
                self.assertGreater(len(remediation.testing_recommendations), 0,
                                 "Remediation plan should have testing recommendations")
                
                # Print first few migration steps
                for i, step in enumerate(remediation.migration_steps[:3]):
                    print(f"    Step {i+1}: {step[:100]}...")
                
            else:
                print(f"⚠️  No vulnerabilities found for {package_name}@{version}, skipping remediation planning")
                
        except Exception as e:
            print(f"❌ Error testing remediation planning: {e}")
            self.fail(f"Failed to test remediation planning: {e}")
        
        print("\n✅ Test 4 completed: Remediation plan generation")
    
    def test_5_report_generation_and_format(self):
        """Test 5: Verify the system generates valid reports in both JSON and Markdown formats."""
        print("\n" + "="*60)
        print("TEST 5: Report Generation and Format")
        print("="*60)
        
        # Test with a known vulnerable package
        package_name, version = "log4j", "2.14.1"
        print(f"\nTesting report generation for: {package_name}@{version}")
        
        try:
            # Scan the package for vulnerabilities
            vulnerabilities = self.scanner.scan_package(package_name, version)
            
            if vulnerabilities:
                # Create a mock repository URL for testing
                repo_url = f"https://github.com/test/{package_name}"
                
                # Generate comprehensive report
                report = {
                    "repository": repo_url,
                    "scan_timestamp": "2025-07-31T12:00:00Z",
                    "vulnerabilities": [vuln.__dict__ for vuln in vulnerabilities],
                    "summary": {
                        "total_vulnerabilities": len(vulnerabilities),
                        "high_severity": len([v for v in vulnerabilities if v.severity == "HIGH"]),
                        "medium_severity": len([v for v in vulnerabilities if v.severity == "MEDIUM"]),
                        "low_severity": len([v for v in vulnerabilities if v.severity == "LOW"]),
                    }
                }
                
                # Test JSON report generation
                json_path = self.scanner.save_report_to_json(report, repo_url)
                print(f"  - JSON report saved to: {json_path}")
                
                # Validate JSON report
                self.assertTrue(os.path.exists(json_path), "JSON report file should exist")
                
                with open(json_path, 'r') as f:
                    json_data = json.load(f)
                
                self.assertIn("repository", json_data)
                self.assertIn("vulnerabilities", json_data)
                self.assertIn("summary", json_data)
                self.assertEqual(len(json_data["vulnerabilities"]), len(vulnerabilities))
                
                # Test Markdown report generation
                md_path = self.scanner.save_report_to_markdown(report, repo_url)
                print(f"  - Markdown report saved to: {md_path}")
                
                # Validate Markdown report
                self.assertTrue(os.path.exists(md_path), "Markdown report file should exist")
                
                with open(md_path, 'r') as f:
                    md_content = f.read()
                
                # Check for required sections in Markdown
                self.assertIn("# Vulnerability Analysis Report", md_content)
                self.assertIn("## Vulnerabilities Found", md_content)
                self.assertIn("## Summary", md_content)
                self.assertIn("## Remediation Plans", md_content)
                
                # Check that vulnerability data is present
                for vuln in vulnerabilities:
                    self.assertIn(vuln.cve_id, md_content)
                
                print(f"  - JSON report size: {os.path.getsize(json_path)} bytes")
                print(f"  - Markdown report size: {os.path.getsize(md_path)} bytes")
                
            else:
                print(f"⚠️  No vulnerabilities found for {package_name}@{version}, skipping report generation")
                
        except Exception as e:
            print(f"❌ Error testing report generation: {e}")
            self.fail(f"Failed to test report generation: {e}")
        
        print("\n✅ Test 5 completed: Report generation and format")
    
    def test_6_neo4j_integration_and_graph_traversal(self):
        """Test 6: Verify the AI agents can properly traverse the dependency graph."""
        print("\n" + "="*60)
        print("TEST 6: Neo4j Integration and Graph Traversal")
        print("="*60)
        
        try:
            # Test Neo4j connection
            print("\nTesting Neo4j connection...")
            
            # Get dependency statistics to verify connection
            stats = self.scanner.get_dependency_statistics()
            
            # Validate statistics structure
            self.assertIsInstance(stats, dict)
            self.assertIn("total_files", stats)
            self.assertIn("total_modules", stats)
            self.assertIn("total_packages", stats)
            self.assertIn("total_relationships", stats)
            
            print(f"  - Total Files: {stats['total_files']}")
            print(f"  - Total Modules: {stats['total_modules']}")
            print(f"  - Total Packages: {stats['total_packages']}")
            print(f"  - Total Relationships: {stats['total_relationships']}")
            
            # Test graph traversal by finding packages
            print("\nTesting graph traversal...")
            packages = self.scanner.get_repository_packages()
            
            self.assertIsInstance(packages, list)
            print(f"  - Found {len(packages)} packages in repository")
            
            if packages:
                # Test finding affected files for a package
                test_package = packages[0]
                print(f"  - Testing affected files for package: {test_package}")
                
                # Create a mock vulnerability for testing
                mock_vuln = VulnerabilityReport(
                    cve_id="CVE-2025-TEST",
                    package_name=test_package,
                    version="1.0.0",
                    severity="HIGH",
                    description="Test vulnerability for graph traversal",
                    cvss_score=8.5,
                    affected_versions="<2.0.0",
                    references=["https://example.com/test"],
                    published_date="2025-01-01",
                    last_modified_date="2025-01-01"
                )
                
                # Test impact analysis (which uses graph traversal)
                impact = self.scanner.analyze_impact(mock_vuln)
                
                self.assertIsInstance(impact, ImpactAnalysis)
                print(f"    - Affected Files: {impact.affected_files}")
                print(f"    - Affected Functions: {impact.affected_functions}")
                print(f"    - Risk Score: {impact.risk_score:.2f}")
            
            else:
                print("  - No packages found in repository")
                
        except Exception as e:
            print(f"❌ Error testing Neo4j integration: {e}")
            self.fail(f"Failed to test Neo4j integration: {e}")
        
        print("\n✅ Test 6 completed: Neo4j integration and graph traversal")
    
    def test_7_end_to_end_workflow(self):
        """Test 7: Verify the complete workflow from dependency scanning to vulnerability analysis."""
        print("\n" + "="*60)
        print("TEST 7: End-to-End Workflow")
        print("="*60)
        
        try:
            # Test the complete workflow with a known vulnerable package
            package_name, version = "log4j", "2.14.1"
            print(f"\nTesting complete workflow for: {package_name}@{version}")
            
            # Step 1: Scan for vulnerabilities
            print("Step 1: Scanning for vulnerabilities...")
            vulnerabilities = self.scanner.scan_package(package_name, version)
            
            if vulnerabilities:
                print(f"  - Found {len(vulnerabilities)} vulnerabilities")
                
                # Step 2: Analyze impact for each vulnerability
                print("Step 2: Analyzing impact...")
                impacts = []
                for vuln in vulnerabilities[:3]:  # Limit to first 3 for testing
                    impact = self.scanner.analyze_impact(vuln)
                    impacts.append(impact)
                    print(f"    - {vuln.cve_id}: Risk Score {impact.risk_score:.2f}, Impact {impact.estimated_impact}")
                
                # Step 3: Generate remediation plans
                print("Step 3: Generating remediation plans...")
                remediations = []
                for vuln in vulnerabilities[:3]:  # Limit to first 3 for testing
                    remediation = self.scanner.generate_remediation_plan(vuln)
                    remediations.append(remediation)
                    print(f"    - {vuln.cve_id}: {len(remediation.migration_steps)} migration steps")
                
                # Step 4: Generate comprehensive report
                print("Step 4: Generating comprehensive report...")
                repo_url = f"https://github.com/test/{package_name}"
                
                report = {
                    "repository": repo_url,
                    "scan_timestamp": "2025-07-31T12:00:00Z",
                    "vulnerabilities": [vuln.__dict__ for vuln in vulnerabilities],
                    "impacts": [impact.__dict__ for impact in impacts],
                    "remediations": [remediation.__dict__ for remediation in remediations],
                    "summary": {
                        "total_vulnerabilities": len(vulnerabilities),
                        "high_severity": len([v for v in vulnerabilities if v.severity == "HIGH"]),
                        "medium_severity": len([v for v in vulnerabilities if v.severity == "MEDIUM"]),
                        "low_severity": len([v for v in vulnerabilities if v.severity == "LOW"]),
                        "average_risk_score": sum(impact.risk_score for impact in impacts) / len(impacts) if impacts else 0,
                    }
                }
                
                # Save reports
                json_path = self.scanner.save_report_to_json(report, repo_url)
                md_path = self.scanner.save_report_to_markdown(report, repo_url)
                
                print(f"  - Reports saved: {json_path}, {md_path}")
                
                # Validate final results
                self.assertGreater(len(vulnerabilities), 0, "Should find vulnerabilities")
                self.assertEqual(len(impacts), min(3, len(vulnerabilities)), "Should have impact analysis for each vulnerability")
                self.assertEqual(len(remediations), min(3, len(vulnerabilities)), "Should have remediation plans for each vulnerability")
                
                # Validate report files exist
                self.assertTrue(os.path.exists(json_path), "JSON report should exist")
                self.assertTrue(os.path.exists(md_path), "Markdown report should exist")
                
                print("✅ Complete workflow executed successfully!")
                
            else:
                print(f"⚠️  No vulnerabilities found for {package_name}@{version}, workflow test limited")
                
        except Exception as e:
            print(f"❌ Error testing end-to-end workflow: {e}")
            self.fail(f"Failed to test end-to-end workflow: {e}")
        
        print("\n✅ Test 7 completed: End-to-end workflow")
    
    def run_all_tests(self):
        """Run all tests and provide a summary."""
        print("\n" + "="*80)
        print("🧪 RUNNING COMPLETE VULNERABILITY SYSTEM TEST SUITE")
        print("="*80)
        
        test_methods = [
            self.test_1_known_vulnerable_package_detection,
            self.test_1b_fastapi_specific_vulnerabilities,
            self.test_2_false_positive_filtering,
            self.test_3_impact_analysis_accuracy,
            self.test_4_remediation_plan_generation,
            self.test_5_report_generation_and_format,
            self.test_6_neo4j_integration_and_graph_traversal,
            self.test_7_end_to_end_workflow,
        ]
        
        passed = 0
        failed = 0
        
        for test_method in test_methods:
            try:
                test_method()
                passed += 1
            except Exception as e:
                failed += 1
                print(f"\n❌ {test_method.__name__} FAILED: {e}")
        
        print("\n" + "="*80)
        print("📊 TEST SUMMARY")
        print("="*80)
        print(f"✅ Tests Passed: {passed}")
        print(f"❌ Tests Failed: {failed}")
        print(f"📈 Success Rate: {passed/(passed+failed)*100:.1f}%")
        
        if failed == 0:
            print("\n🎉 ALL TESTS PASSED! The vulnerability system is working correctly.")
        else:
            print(f"\n⚠️  {failed} test(s) failed. Please review the errors above.")
        
        return passed, failed


def main():
    """Main function to run the test suite."""
    print("🧪 Vulnerability System Test Suite")
    print("="*50)
    
    # Create test instance
    test_suite = TestVulnerabilitySystem()
    
    # Set up test environment
    test_suite.setUp()
    
    try:
        # Run all tests
        passed, failed = test_suite.run_all_tests()
        
        # Return appropriate exit code
        return 0 if failed == 0 else 1
        
    finally:
        # Clean up
        test_suite.tearDown()


if __name__ == "__main__":
    exit(main()) 